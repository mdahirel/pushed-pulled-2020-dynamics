---
title: 'Trichogramma range expansions (genetics and dynamics): 1- empirical data,  main text'
author: "Maxime Dahirel"
date:
output: 
  html_document:
    theme: yeti
    toc: TRUE
    toc_float: TRUE
    code_download: TRUE
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, eval = FALSE)
```

```{r load-packages}
library(arm) # for invlogit()

library(tidyverse)

library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = 2) # change to number of cores (I think threads, actually) you want to use in parallel while fitting models
library(brms)
library(bayesplot)
library(tidybayes)

library(cowplot)
library(ggtext)
library(patchwork)

library(adegenet)

library(here)
```

# Introduction

## Aims of project 
To understand how the position of a range expansion on a (putative) pushed/pulled gradient influences its spread dynamics and evolution

## General methods (see preprint or article for full details)

24 experimental linear landscapes were created, consisting in patches/vials connected by tubes. Each patch contains ~450 host eggs as resource, replenished at each generation.

*Trichogramma brassicae* individuals were introduced in the initial patch, and the experiment ran for 14 generations, counting the starting individuals. 

At each generation, adults were left free to move and reproduce for 48 hours before being removed. These collected adults were then used as source of genetic information (this document), and as sources of further offspring for another experiment. Patches were added to the end of each landscape as needed, so there was always at least two empty patches at the front. 

We expected that (at low population sizes) reduced connectivity should lead to increased stochasticity in dispersal success and establishment difficulties:

```{r proof-of-principle}
# proof of principle that reduced dispersal restricts spread to new patches more at low N, due to properties of the binomial distribution
plot_a <- expand_grid(dispersal.rate = c(0.05, 0.1, 0.2, 0.4), N = 1:500) %>%
  mutate(label = if_else(N == min(N), paste("*D* = ", dispersal.rate, sep = ""), NA_character_)) %>%
  ggplot() +
  geom_line(aes(x = N, y = 1 - pbinom(0, N, dispersal.rate), col = dispersal.rate, group = dispersal.rate), size = 1.2) +
  scale_y_continuous(name = "Probability that at least one individual disperses") +
  scale_x_log10(name = "Population size before dispersal phase", breaks = c(1, 2, 5, 10, 20, 50, 100, 200, 500), limits = c(0.4, 500)) +
  scale_color_gradient(name = "Mean dispersal rate", low = "black", high = "grey60") +
  geom_textbox(aes(x = N, y = dispersal.rate, label = label), width = 0.15, box.padding = unit(c(1, 0, 1, 0), "pt"), halign = 0.5, hjust = 1, vjust = 0) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95") +
  theme(legend.position = "none")
### the effect vanishes around N=100 and become strong at N < 10 so probably too rare to be detected in previous simulation studies with K in tens of thousands
### corollary: the lower the dispersal rate, the bigger the population needs to be to guarantee a given probability (let's say 50%) of at least one individual dispersing
### 

# we can also see that reducing dispersal rate increase its variability, another argument
plot_b <- expand_grid(dispersal.rate = c(0.05, 0.1, 0.2, 0.4), N = 1:500) %>%
    mutate(label = if_else(N == min(N), paste("*D* = ", dispersal.rate, sep = ""), NA_character_)) %>%
    ggplot() +
    geom_line(aes(x = N, y = sqrt(dispersal.rate*(1-dispersal.rate)*N)/(N*dispersal.rate), col = dispersal.rate, group = dispersal.rate), size = 1.2) +
    scale_y_continuous(name = "Coefficient of variation (mean number of dispersers)",limits=c(0,5)) +
    scale_x_log10(name = "Population size before dispersal phase", breaks = c(1, 2, 5, 10, 20, 50, 100, 200, 500), limits = c(0.4, 500)) +
    scale_color_gradient(name = "Mean dispersal rate", low = "black", high = "grey60") +
    geom_textbox(aes(x = N, y = sqrt(dispersal.rate*(1-dispersal.rate)*N)/(N*dispersal.rate), label = label), width = 0.15, box.padding = unit(c(1, 0, 1, 0), "pt"), halign = 0.5, hjust = 1, vjust = 0) +
    theme_half_open(11) +
    background_grid(colour.major = "grey95", colour.minor = "grey95") +
    theme(legend.position = "none")

((plot_a + 
    scale_x_log10("", breaks = c(1, 2, 5, 10, 20, 50, 100, 200, 500), limits = c(0.4, 500)))/plot_b) +
  plot_annotation(tag_levels="A")




```

As a consequence, at the (relatively) low population sizes that interest us, reducing connectivity should lead expansions towards "pushed" dynamics, so two types of landscapes were set up: "reference" dispersal, with two tubes connecting successive patches, and "restricted" dispersal, with only one tube. They were hypothesized to lead to __relatively__ pulled and pushed dynamics, respectively. 12 landscapes were under putatively pushed dynamics, 12 under putatively pulled dynamics.

We have obtained two sources of information:

- __genetic information__ is obtained by genotyping adult wasps every ~4 generations (release generation a.k.a G0, and G4,8,12) at 19 microsatellite loci.
- __population dynamics information__ (population size and spread of the expansion) is obtained by photographing egg plates every generation right when they become brown-black if parasitized. Photographs are then analysed using `ImageJ` and `Codicount` to obtain estimated % of parasitism. Each image is analysed by 4 macros trained on different data ; patches are scanned by humans prior to photographs, patches with no black eggs are directly counted as zeros and thus not present in the dataset. In the main text of the manuscript (and the present document), we only use this file to get information on the location of the most advanced patch (to estimate velocity).

# Analysis

## Loading datasets

```{r load-dataset}

### import raw datasets
raw_dynamics <- read_csv(here("data/Trichogramma_dynamics.csv"))

raw_genetics <- read_csv(here("data/Trichogramma_genetics.csv"),
  col_types = cols(.default = col_character())
)
## forcing locus columns to be character, otherwise some important leading zeroes are lost ( a 090090 individual _homozygote with two "090" alleles_ becomes 90090, 000000 becomes 0)
## there are other way to do it by doing it downscript (see e.g. stringr::str_pad()) but best to do it right at the outset
```


The `raw_dynamics` dataset contains the following variables:

- `Generation` : number of generations since release into experimental landscapes (initially released individuals have `Generation` = 0)

- `Bloc` : experimental setup block, not used

- `Macro` : 4 macros used in `codicount` to estimate parasitism rates (see manuscript and Supplementary Material). Macro name indicates the generation on which the macro was initially trained

- `Image` : file name, structured as `[genetic mix ID][Treatment ID][Replicate sub-ID]_[Patch ID]`. Replicate sub-ID are non-unique (they are repeated across Mix and Treatments), patch ID correspond to distance from the release patch (0 = release patch).

- `Total_surface`, `B` `H` and `P` : photograph surface (in pixels), as well ass number of pixels classified as Background, Healthy and Parasitised

- `P_black` : `P` /(`P` + `H`), parasitism rate

- `obs_count` : number of parasitized eggs, human-counted. Used to validate the `codicount` macros

The `raw_genetics` dataset has two types of variables:

- `ID` : a unique individual ID structured as `G[generation]_[genetic mix ID][Treatment ID]_[Replicate sub-ID][patch location]_[Individual sub-ID]` . Individual and replicate sub-ID are non-unique (they are repeated across Mix and Treatments)(patch location is absent _ but not needed _ from G0 IDs)

- `TB[X]` where [X] is a number (19 columns, 6-digit strings) : Individual genotype at microsatellite locus `TB[X]`. Each allele is described by a 3-digit string, so each value corresponds to the 2 alleles pasted together. "000" = "missing allele".


## Data preprocessing

### Dataset front: speed of the advancing range expansions

We first play with the dynamics dataset. From the raw dataset we want to produce a `data_front` dataset, to estimate how fast the wave fronts advance

We first extract useful variables from the `Image` string, and recode some other variables. For instance, treatments are coded as `PL` (reference) and `PS` (restricted connectivity) in the dataset, based on the expected regimes (*more* PuLled and *more* PuShed, respectively). Recoded to be accurate regardless of actual results. Then we use the fact that only patches with actually parasitized eggs are in the raw dataset to get the front location in each landscape at each time: it is simply the location of the farthest populated patch:

```{r data-front}
data_front <- raw_dynamics %>%
  mutate(
    Mix = as.numeric(str_sub(Image, 1, 1)),
    Treatment = str_sub(Image, 2, 3),
    Replicate = as.numeric(str_sub(Image, 4, 4)),
    Patch = as.numeric(str_sub(Image, 6, 7))
  ) %>%
  # no further processing needed; we exploit the fact that chars 6&7 are either digit-dot (patchs 0 to 9)
  # or digit-digit (patches 10 and beyond)
  # as.numeric() resolves both correctly (e.g; "2." and "12" become 2 and 12)
  mutate(
    landscapeID = paste("Mix", Mix, "_Treatment", Treatment, "_Replicate", Replicate, sep = ""), # a unique replicate ID
    Treatment = fct_recode(Treatment, `reference` = "PL", `reduced connectivity` = "PS")
  ) %>%
  group_by(landscapeID, Mix, Treatment, Generation) %>%
  summarise(front = max(Patch)) %>%
  ungroup() %>%
  group_by(landscapeID) %>%
  arrange(Generation) %>%
  complete(nesting(Mix, Treatment, landscapeID),
    Generation = 0:13, fill = list(front = 0)
  ) %>% ## just so we have a generation 0 point (i.e. release) for pretty plotting
  ungroup()
```


### Dataset genetics: dynamics of neutral genetic diversity during expansion

Then we turn to the genetics data. We're only going to generate one analysis dataset here, by converting individual microsatellite info into population/patch-level multilocus expected heterozygosity data, as our measure of genetic diversity.

We're going to do it in two steps: an intermediate dataset where we again extract useful variables from the `ID` string, and recode some other variables...

```{r data-genetics-1}

### STEP 1 extract relevant variables from the ID string

data_genetics <- raw_genetics %>%
  mutate( ### info on variables is contained in each sample ID
    Generation = str_extract(ID, "G0|G4|G8|G12"),
    Mix = str_extract(ID, "_1P|_2P|_3P"),
    Treatment = str_extract(ID, "PL|PS"),
    Replicate = str_extract(ID, "L_[:digit:]|S_[:digit:]"),
    Location = str_extract(ID, "C|F")
  ) %>%
  mutate(
    Generation = as.numeric(str_extract(Generation, "0|4|8|12")),
    Mix = as.numeric(str_extract(Mix, "1|2|3")),
    Replicate = as.numeric(str_extract(Replicate, "[:digit:]")),
    Location = fct_recode(Location, core = "C", edge = "F")
  ) %>%
  mutate(Location = as.character(Location)) %>%
  mutate(Location = replace_na(Location, "origin (x = 0, t = 0)")) %>% ## samples that are neither core nor edge are from the origin (G0)
  mutate(Location = factor(Location), landscapeID = paste("Mix", Mix, "_Treatment", Treatment, "_Replicate", Replicate, sep = "")) %>%
  mutate(spacetimeID = paste(landscapeID, "_Generation", Generation, "_Location", Location, sep = "")) %>% # unique population (landscape x patch location x time) ID
  mutate(
    is.edge = -0.5 * (Location == "core") + 0.5 * (Location == "edge"), ## dummy variable to make interpreting interaction coefs easier
    Treatment = fct_recode(Treatment, `reference` = "PL", `reduced connectivity` = "PS")
  )
```

Then we convert allele columns in a format that allows us to calculate expected heterozygosity (STEP 2 below) and do that (+ some tidying, STEP 3 below):

```{r data-genetics-2}
### STEP 2 isolate the genetics markers
genmat <- df2genind(select(data_genetics, starts_with("TB")), ## all allelic columns start with a "TB"
  ncode = 3, ## ncode=3 bc 3 characters for one allele
  NA.char = "000", ## missing alleles
  ind.names = data_genetics$ID, pop = data_genetics$spacetimeID
)
## there will be a warning because 1 individual has missing info for all loci, it's OK

### STEP 3 generate patch-level final table ; one row = one sampled patch
data_genetics <- data_genetics %>%
  group_by(spacetimeID) %>%
  mutate(Nsampled = length(Location)) %>%
  ungroup() %>%
  select(-starts_with("TB"), -ID) %>%
  distinct() %>%
  inner_join(
    tibble(Hexp = Hs(genmat), spacetimeID = names(Hs(genmat)))
  )

# nInd(genmat)
# seppop(genmat) %>% map(.x,.f=~nInd(.x)) %>% unlist() %>% tibble(N=.) %>% summarise(mean=mean(N),sd=sd(N),min=min(N),max=max(N))
# useful to get the number of individuals on which we have information (the second line per patch x time combination)
```

Our metric of genetic diversity (expected heterozygosity) is stored in `Hexp`.

## Data analysis

Now we have everything we need, we can fit some models! (see manuscript for details)


### Dataset front: speed of the advancing range expansions

We here assume each front initially advances at a speed that may not be the asymptotic/equilibrium speed (which is what interests us), due to various stochastic reasons, but end up converging to it more or less exponentially:

```{r model-front}

if (file.exists(here("R_output", "model1_front_expe.Rdata")))  {
# this if-else statement is avoid re-fitting a model when knitting Rmd file if there is already one existing in R_output
# to override, re-run the model and re-save manually by selecting relevant code lines then knit (or delete the Rdata object)

    load(here("R_output", "model1_front_expe.Rdata"))
  } else {
  bf_front <- bf(front ~ log(speed * Generation),
    nlf(speed ~ speedasym + (speedstart - speedasym) * exp(-(Generation - 1) * rate)),
    ## Generation - 1 because moving the startspeed away from t=0 (where it doesn't actually exist) to t=1 stabilises everything
    nlf(rate ~ 10^(lograte)),
    nlf(speedasym ~ exp(logspeedasym)),
    nlf(speedstart ~ exp(logspeedstart)),
    logspeedasym ~ 0 + Treatment + (1 | 1 | landscapeID),
    logspeedstart ~ 0 + Treatment + (1 | 1 | landscapeID),
    lograte ~ 0 + Treatment + (1 | 1 | landscapeID),
    family = lognormal, nl = TRUE
  )

  prior_front <- c(
    set_prior("normal(0,1)", nlpar = c("logspeedasym", "logspeedstart", "lograte"), class = "b"),
    set_prior("normal(0,1)", nlpar = c("logspeedasym", "lograte", "logspeedstart"), class = "sd"),
    set_prior("normal(0,1)", class = "sigma"),
    set_prior("lkj(2)", class = "cor")
  )

  mod_front <- brm(bf_front,
    data = subset(data_front, Generation > 0), chains = 4, iter = 4000, warmup = 2000,
    prior = prior_front, control = list(adapt_delta = 0.95),
    seed = 42
  )
  

  loo_mod_front<-loo(mod_front,
                     reloo=TRUE) #a few problematic obs identified, so redone with reloo
  
  save(list = c("mod_front","loo_mod_front"), file = here("R_output", "model1_front_expe.Rdata"))
}
```

Ideally, we would have used a distribution actually accounting for the discrete nature of front locations values. We could have tried to fit a Poisson model instead of a lognormal one, but that would have been trading an approximation for another: data are **under**dispersed relative to the equivalent Poisson model (you can change the family in `mod_front` to poisson and check this). A [Conway Maxwell Poisson]( https://discourse.mc-stan.org/t/brms-and-conway-maxwell-poisson-distribution/7368/15) may solve this, but it's not 100% implemented yet in `brms`, and may be overkill, so we stay with the lognormal approximation. Results under lognormal or Poisson are close to identical anyway.

Before we go forward, we need to check whether a power decay in the non-linear formula wouldn't be more appropriate.

```{r model-front-power}

if (file.exists(here("R_output", "model1bis_front_expe_power.Rdata"))){
# this if-else statement is avoid re-fitting a model when knitting Rmd file if there is already one existing in R_output
# to override, re-run the model and re-save manually by selecting relevant code lines then knit (or delete the Rdata object)

    load(here("R_output", "model1bis_front_expe_power.Rdata"))
  } else {
bf_front2 <- bf(front ~ log(speed * Generation),
               nlf(speed ~ speedasym + (speedstart - speedasym) * (Generation)^(-rate) ),
               nlf(rate ~ 10^(lograte)),
               nlf(speedasym ~ exp(logspeedasym)),
               nlf(speedstart ~ exp(logspeedstart)),
               logspeedasym ~ 0 + Treatment + (1 | 1 | landscapeID),
               logspeedstart ~ 0 + Treatment + (1 | 1 | landscapeID),
               lograte ~ 0 + Treatment + (1 | 1 | landscapeID),
               family = lognormal, nl = TRUE
)

prior_front2 <- c(
  set_prior("normal(0,1)", nlpar = c("logspeedasym", "logspeedstart"), class = "b"),
  set_prior("normal(0,1)", nlpar = c("lograte"), class = "b"),
  set_prior("normal(0,1)", nlpar = c("logspeedasym", "lograte", "logspeedstart"), class = "sd"),
  set_prior("normal(0,1)", class = "sigma"),
  set_prior("lkj(2)", class = "cor")
)

mod_front2 <- brm(bf_front2,
                 data = subset(data_front, Generation > 0), chains = 4, iter = 6000, warmup = 3000,
                 prior = prior_front2, control = list(adapt_delta = 0.95, max_treedepth=15),
                 seed = 42
)


  loo_mod_front2<-loo(mod_front2,
                      reloo=TRUE) #some problematic obs identified, so redone with reloo
  
  save(list = c("mod_front2","loo_mod_front2"), file = here("R_output", "model1bis_front_expe_power.Rdata"))
}
```


Let's compare the two:

```{r comparison-model-front}
loo_compare(loo_mod_front,loo_mod_front2)
```

There is a slight advantage to the "power decay" model, but not conclusive (difference is less than 2 SEs). Because the "exponential decay" model has a very conclusive advantage for the *simulated* data, (see script 3) let's use it for the empirical data also, for consistency. Anyway, as the reader can see by looking at the model summaries, our qualitative conclusions for the empirical data don't change whether we use the power or exponential model (no detectable difference in asymptotic velocity in both cases). (The power model does tend to predict lower asymptotic speeds overall)

Now let's have a look at the exponential model:

```{r summary-model-front}

summary(mod_front)

### The default summary prints posterior means and quantile intervals. What if we want HD Intervals instead?
summary_front <- mod_front %>%
  posterior_samples() %>%
  select(starts_with(c("Intercept", "b_", "sd_", "cor_", "sigma"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  print(n = Inf)

mcmc_rank_overlay(mod_front, pars = summary_front$name) # check chains have converged

### prediction intervals around each point
ppc_ribbon(
  yrep = predict(mod_front, summary = FALSE),
  x = rank(predict(mod_front)[, 1]),
  y = subset(data_front$front, data_front$Generation > 0),
  prob = 0.5, prob_outer = 0.95
)
```

### Dataset genetics: dynamics of neutral genetic diversity during expansion

Our model here is rooted in theory (see manuscript for references) and assumes genetic diversity declines exponentially through time. The decay rate parameter is our parameter of interest here:

```{r model-genetics}
if (file.exists(here("R_output", "model2_genet_expe.Rdata"))) {
  load(here("R_output", "model2_genet_expe.Rdata"))
} else {
  prior_genetics <- c(
    ## only a part of the prior, so it can be used in several models that share several parameters, but not all
    ## the remainder is in each brm() call
    set_prior("normal(0,1.5)", nlpar = c("logitH0"), class = "b"),
    set_prior("normal(0,1)", nlpar = c("logdecay"), class = "b"),
    set_prior("normal(0,1)", nlpar = c("logdecay", "logitH0"), class = "sd"),
    set_prior("lkj(2)", class = "cor")
  )

  bf_genetics <- bf(logit(Hexp) ~ logit(H0 * exp(-decay * Generation)),
    nlf(H0 ~ inv_logit(logitH0)),
    nlf(decay ~ 10^(logdecay)),
    logitH0 ~ 1 + (1 | 1 | landscapeID),
    logdecay ~ 0 + Treatment + Treatment:is.edge + (is.edge | 1 | landscapeID),
    family = student(), nl = TRUE
  )

  mod_genetics <- brm(bf_genetics,
    data = data_genetics,
    chains = 4, iter = 4000, warmup = 2000,
    prior = c(
      prior_genetics,
      set_prior("normal(0,1)", class = "sigma"),
      set_prior("gamma(2,0.1)", class = "nu")
    ),
    seed = 42, control = list(adapt_delta = 0.8)
  )

  # the gamma(2, 0.1) prior for nu follows recommendations from the Stan wiki
  # https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations

  save(list = "mod_genetics", file = here("R_output", "model2_genet_expe.Rdata"))
}
```

```{r summary-model-genetics}
summary(mod_genetics)

summary_genetics <- mod_genetics %>%
  posterior_samples() %>%
  select(starts_with(c("Intercept", "b_", "sd_", "cor_", "sigma", "nu"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  print(n = Inf)

mcmc_rank_overlay(mod_genetics, pars = summary_genetics$name)

### prediction intervals around each point
ppc_ribbon(
  yrep = invlogit(predict(mod_genetics, summary = FALSE)),
  x = rank(predict(mod_genetics)[, 1]),
  y = data_genetics$Hexp,
  prob = 0.5, prob_outer = 0.95
)
```

#### Aside:  why use a logit-Student model, and not simply a Beta model (or a logit-normal)?  

Well, we did both, and the former outperforms the others, maybe because it accounts better for rare outliers (like sudden **increases** in diversity with time) that are visible on plots (which would be expected due to sampling when selecting individuals before genotyping, or due to the expansion process itself):

```{r model-genetics-beta}
if (file.exists(here("R_output", "model2bis_genet_expe.Rdata"))) {
  load(here("R_output", "model2bis_genet_expe.Rdata"))
} else {
  bf_genetics2 <- bf(Hexp ~ logit(H0 * exp(-decay * Generation)),
    nlf(H0 ~ inv_logit(logitH0)),
    nlf(decay ~ 10^(logdecay)),
    logitH0 ~ 1 + (1 | 1 | landscapeID),
    logdecay ~ 0 + Treatment + Treatment:is.edge + (is.edge | 1 | landscapeID),
    nlf(phi ~ 1 / invphi),
    invphi ~ 1,
    family = Beta(link_phi = "identity"), nl = TRUE
  )

  mod_genetics2 <- brm(bf_genetics2,
    data = data_genetics,
    chains = 4, iter = 4000, warmup = 2000,
    prior = c(
      prior_genetics,
      set_prior("normal(0,1)", nlpar = "invphi", lb = 0)
    ),
    seed = 42, control = list(adapt_delta = 0.9)
  )

  # the prior and transformation choices for phi are inspired by the Stan wiki
  # https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations

  save(list = "mod_genetics2", file = here("R_output", "model2bis_genet_expe.Rdata"))
}
## can't compare both models directly with LOO since the responses are not the same, logit(Hexp) versus Hexp
## but let's check their performance:

pp_check(mod_genetics, type = "loo_pit_overlay", nsamples = 2000)

pp_check(mod_genetics2, type = "loo_pit_overlay", nsamples = 2000)

## some evidence that the Beta model is slightly more miscalibrated compare to the Student on logits
## can also be seen using type="loo_pit_qq"
#####
```

While we can't directly compare the Student model on logits and the Beta model with LOO, we can compare the student with a Gaussian model on logits, which should be close to a Beta model in terms of behaviour:


```{r model-genetics-logit-normal}
if (file.exists(here("R_output", "model2ter_genet_expe.Rdata"))) {
  load(here("R_output", "model2ter_genet_expe.Rdata"))
} else {
  bf_genetics3 <- bf(logit(Hexp) ~ logit(H0 * exp(-decay * Generation)),
    nlf(H0 ~ inv_logit(logitH0)),
    nlf(decay ~ 10^(logdecay)),
    logitH0 ~ 1 + (1 | 1 | landscapeID),
    logdecay ~ 0 + Treatment + Treatment:is.edge + (is.edge | 1 | landscapeID),
    family = gaussian, nl = TRUE
  )

  mod_genetics3 <- brm(bf_genetics3,
    data = data_genetics,
    chains = 4, iter = 4000, warmup = 2000,
    prior = c(
      prior_genetics,
      set_prior("normal(0,1)", class = "sigma")
    ),
    seed = 42, control = list(adapt_delta = 0.99)
  )

  save(list = "mod_genetics3", file = here("R_output", "model2ter_genet_expe.Rdata"))
}

## looking at
## summary(mod_genetics)
## summary(mod_genetics2)
## summary(mod_genetics3)
## confirms that the logit-normal behaves more or less like the Beta re: parameter values

pp_check(mod_genetics, type = "loo_pit_overlay", nsamples = 200)

pp_check(mod_genetics2, type = "loo_pit_overlay", nsamples = 200)

pp_check(mod_genetics3, type = "loo_pit_overlay", nsamples = 200)

## the LOO PIT graphs too
## , so now let's compare logit student and logit normal:


if (file.exists(here("R_output", "loo_genet_expe.Rdata"))) {
  load(here("R_output", "loo_genet_expe.Rdata"))
} else {
  loo1 <- loo(mod_genetics, reloo = TRUE)

  loo3 <- loo(mod_genetics3, reloo = TRUE) ## reloo = TRUE needed because some "problematic" obs with high pareto_k

  save(list = c("loo1", "loo3"), file = here("R_output", "loo_genet_expe.Rdata"))
}

loo_compare(loo1, loo3)

table( (loo1$pointwise[, "elpd_loo"] - loo3$pointwise[, "elpd_loo"]) > 0)
## adds to evidence that logit-student is better
#####
```

### Relationship between *K* and *v*

It has been predicted and shown (http://doi.org/10.1101/307322) that the presence of a relationship between the carrying capacity/equilibrium population density *K* and the velocity of the expansion could be indicative of pushed expansions. If we want to test that with our data we need good estimates of replicate-level asymptotic *v* and *K*. We already have the former (see above), to have the latter we'll need to model population size. Then we can test whether the correlation is or isn't treatment-dependent by fitting a bivariate model.

#### Univariate model(s) for *K*

The first step is to find a satisfactory univariate model for *K*. We're going to use the population size in the starting patch (x=0) as a proxy, since we are reasonably certain it is at equilibrium density from the start, contrary to other patches:

```{r pop-size-data}
data_popsize <- raw_dynamics %>%
  mutate(
    Mix = as.numeric(str_sub(Image, 1, 1)),
    Treatment = str_sub(Image, 2, 3),
    Replicate = as.numeric(str_sub(Image, 4, 4)),
    Patch = as.numeric(str_sub(Image, 6, 7))
  ) %>%
  # no further processing needed; we exploit the fact that chars 6&7 are either digit dot (patches 0 to 9)
  # or digit-digit (patches 10 and beyond)
  ## as.numeric() resolves both correctly (e.g; "2." and "12" become 2 and 12)
  mutate(landscapeID = paste("Mix", Mix, "_Treatment", Treatment, "_Replicate", Replicate, sep = "")) %>% # a unique replicate ID
  mutate(
    Peggs_est = P / (P + H), ## proportion of pixels counted as parasitised (estimated)
    spacetimeID = paste(landscapeID, "_Generation", Generation, "_Patch", Patch, sep = ""), # a unique ID for each replicate x patch x generation combination
    Mix = factor(Mix)
  ) %>%
  mutate(Treatment = fct_recode(Treatment, `reference` = "PL", `reduced connectivity` = "PS")) %>% 
  filter(Patch==0) %>%  #we only keep the starting patch
  select(Treatment,landscapeID,Generation,Peggs_est,Macro) %>%
  left_join(data_front) #add front info for the bivariate model
```

Since we measured population size as a % of "egg pixels" parasitised, we're going to start with a Beta model, where measured population size depends on treatment, among replicate variation and observer (Macro) effects:

```{r}
if (file.exists(here("R_output", "model3_popsize_expe.Rdata"))) {
  load(here("R_output", "model3_popsize_expe.Rdata"))
} else {
  mod_popsize <- brm(bf(
    Peggs_est ~ 0 + Treatment + (1 | Macro) + (1 | landscapeID),
    nlf(phi ~ 1 / invphi),
    invphi ~ 1
  ),
  data = data_popsize, family = Beta(link_phi = "identity"),
  iter = 6000, warmup = 3000, chains = 4,
  prior = c(
    set_prior("normal(0,1.5)", class = "b"),
    set_prior("normal(0,1)", class = "sd"),
    set_prior("normal(0,1)", nlpar = "invphi", lb = 0)
  ),
  control = list(adapt_delta = 0.99, max_treedepth = 15), seed = 42
  )
  
  save(list = "mod_popsize", file = here("R_output", "model3_popsize_expe.Rdata"))
}

pp_check(mod_popsize) ##look at the other pp_check types too

#loo1<-loo(mod_popsize,save_psis=TRUE)
#
#ppc_loo_pit_overlay(
#  yrep = predict(mod_popsize, summary = FALSE),
#  y = data_popsize$Peggs_est,
#  lw = weights(loo1$psis)
#)
```

It looks like this model does not reproduce the data very well, at all. Maybe we should do like with genetic diversity and use a student model on the logits instead?

```{r}
if (file.exists(here("R_output", "model3bis_popsize_expe.Rdata"))) {
  load(here("R_output", "model3bis_popsize_expe.Rdata"))
} else {
  mod_popsize2 <- brm(bf(logit(Peggs_est) ~ 0 + Treatment + (1 | Macro) + (1 | landscapeID)),
  data = data_popsize, family = student,
  iter = 6000, warmup = 3000, chains = 4,
  prior = c(
    set_prior("normal(0,1.5)", class = "b"),
    set_prior("normal(0,1)", class = "sd"),
  set_prior("normal(0,1)", class = "sigma"),
  set_prior("gamma(2,0.1)", class = "nu")
  ),
  control = list(adapt_delta = 0.99, max_treedepth = 15), seed = 42
  )


  save(list = "mod_popsize2", file = here("R_output", "model3bis_popsize_expe.Rdata"))
}

pp_check(mod_popsize2) + lims(x=c(-5,5)) ##look at the other pp_check too

###previous plot is on the logit scale, let's backtransform to be able to compare to the first model


ppc_dens_overlay(
  yrep = invlogit(predict(mod_popsize2, summary = FALSE))[1:10,], #display only the first 10 posteriors, like in the pp_check default
  y = data_popsize$Peggs_est
)


#loo2<-loo(mod_popsize2,save_psis=TRUE)
#ppc_loo_pit_overlay(
#  yrep = predict(mod_popsize2, summary = FALSE),
#  y = logit(data_popsize$Peggs_est),
#  lw = weights(loo2$psis)
#)


```

It does look much better. Still not perfect, but better

```{r}
summary(mod_popsize2)

posterior_samples(mod_popsize2) %>%  ##get coefficient posteriors 
  select(contains("b_")) %>%             ##keep only fixed effects
  mutate(.iteration = 1:dim(.)[1]) %>% 
  pivot_longer(cols=-.iteration) %>% 
  compare_levels(variable="value",by="name") %>% 
  mean_hdi()
```

The conclusion from the second model is that there is no clear evidence that treatment influences the average *K* (although there are hints of an increase with reduced connectivity that may be worth exploring in future studies _ note that the first model `mod_popsize` would conclude that this increase does exist). 


#### A bivariate model for *K* and *v*

Now we can use the model formulas previously selected for the asymptotic speed *v* and for *K*, to test whether among-replicate variation in *K* is linked to among-replicate variation in *v*, and whether this correlation depends on treatment. We can do that by refitting the previous univariate models into a bivariate model, with a slight alteration to the replicate-level random-effects for *K* and *v* to make their (co)variance treatment-specific:

```{r}
bf_popsize<- bf(logit(Peggs_est) ~ 0 + Treatment + (1 | Macro) + (1 | 1 | gr(landscapeID,by=Treatment)), family = student)

bf_front <- bf(front|subset(Macro=="MacroG2") ~ log(speed * Generation),
               ##we use subset() because the front is the same for all Macros, we don't want duplicates
               nlf(speed ~ speedasym + (speedstart - speedasym) * exp(-(Generation - 1) * rate)),
               nlf(rate ~ 10^(lograte)),
               nlf(speedasym ~ exp(logspeedasym)),
               nlf(speedstart ~ exp(logspeedstart)),
               logspeedasym ~ 0 + Treatment + (1 | 1 | gr(landscapeID,by=Treatment)),
               logspeedstart ~ 0 + Treatment + (1 | 1 | gr(landscapeID,by=Treatment)),
               lograte ~ 0 + Treatment + (1 | 1 | gr(landscapeID,by=Treatment)),
               family = lognormal, nl = TRUE
)

prior = c(
  set_prior("normal(0,1.5)", class = "b",resp="logitPeggsest"),
  set_prior("normal(0,1)", class = "sd",resp="logitPeggsest"),
  set_prior("normal(0,1)", class = "sigma",resp="logitPeggsest"),
  set_prior("gamma(2,0.1)", class = "nu",resp="logitPeggsest"),
  set_prior("normal(0,1)", nlpar = c("logspeedasym", "logspeedstart", "lograte"), class = "b",resp="front"),
  set_prior("normal(0,1)", nlpar = c("logspeedasym", "lograte", "logspeedstart"), class = "sd",resp="front"),
  set_prior("normal(0,1)", class = "sigma",resp="front"),
  set_prior("lkj(2)", class = "cor")
)

if (file.exists(here("R_output", "model4_Kv_expe.Rdata"))) {
  load(here("R_output", "model4_Kv_expe.Rdata"))
} else {

mod_K_v <- brm(mvbf(bf_front+bf_popsize),
                 data = data_popsize, chains = 4, iter = 6000, warmup = 3000,
                 prior = prior, control = list(adapt_delta = 0.99, max_treedepth=15),
                 seed = 42
)

## If Rstan is used as the backend (the default in brms as of 2020-11-15)
## the warnings that may pop up when the model is done with the settings above can _ for once!!_ be ignored. 
## See https://github.com/paul-buerkner/brms/issues/865
## summary(mod_K_v) will show that all parameters of interest are fine
## and exploration of the inner parts of the model object shows that the parameters that trigger the warnings 
## are more or less *expected* to give NAs (see issues in link)
## these warnings stem from choices in the Rstan interface
## and "disappear" when CmdStanR is used instead of RStan as backend

  save(list = "mod_K_v", file = here("R_output", "model4_Kv_expe.Rdata"))
}
```

## Postprocessing : plots and summaries

Now we can draw the figures associated with these models, and maybe get back some useful comparisons at the same time?

```{r color-palettes}

TRTpalette <- c("#d8b365", "#5ab4ac")
edgecorePalette <- c("#998ec3", "#f1a340", "#000000") # 3 colors, for core, edge and origin (black) patches
```

### Dataset front: speed of the advancing range expansions

```{r figure-front}
## PART 1 : advance of the fronts through time, predicted and observed
p1 <- data_front %>%
  mutate(landscapeID = landscapeID[1]) %>% ## arbitrary, ignored for prediction, there just needs to be a value ##may not even be needed on later tidybayes versions, to check
  select(Treatment, landscapeID) %>%
  distinct() %>%
  expand_grid(Generation = (1:130) / 10) %>%
  add_fitted_draws(mod_front, re_formula = NA) %>%
  ungroup() %>%
  ggplot() +
  stat_lineribbon(aes(x = Generation, y = .value, fill = Treatment), .width = 0.95, alpha = 0.5, point_interval = mean_hdi) +
  geom_line(data = data_front, aes(x = Generation, y = front, group = landscapeID, col = Treatment)) +
  scale_fill_manual(values = TRTpalette) +
  scale_colour_manual(values = TRTpalette) +
  scale_y_continuous("Front location (patches from release)") +
  facet_wrap(~Treatment) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95")


## PART 2: posterior of the key parameter: asymptotic speed
p2 <- data_front %>%
  mutate(landscapeID = landscapeID[1], Generation = 1) %>% ## arbitrary, ignored for prediction, there just need to be a value
  select(Treatment, landscapeID, Generation) %>%
  distinct() %>%
  add_fitted_draws(mod_front, nlpar = "logspeedasym", re_formula = NA) %>%
  mutate(.value = exp(.value)) %>% ## backtransformation
  ungroup() %>%
  ggplot() +
  stat_eye(aes(x = Treatment, y = .value, fill = Treatment), slab_alpha = 0.9, .width=c(0.001,0.95), point_interval = mean_hdi) +
  scale_fill_manual(values = TRTpalette) +
  scale_x_discrete("Landscape type") +
  scale_y_continuous("Mean asymptotic velocity (patches/generation)") +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95")



p1 / p2 + plot_annotation(tag_levels = "A") + plot_layout(guides = "collect") &
  theme(legend.position = "none")
```


```{r velocity-comparison}
data_front %>%
  ungroup() %>%
  mutate(landscapeID = landscapeID[1], Generation = 1) %>%
  select(Treatment, landscapeID, Generation) %>%
  distinct() %>%
  add_fitted_draws(mod_front, nlpar = "logspeedasym", re_formula = NA) %>%
  mutate(.value = exp(.value)) %>% ## backtransformation
  compare_levels(variable = .value, by = Treatment) %>%
  mean_hdi() # no differences
```


### Dataset genetics: dynamics of neutral genetic diversity during expansion

```{r figure-genetics}


p1 <- data_genetics %>%
  mutate(landscapeID = landscapeID[1]) %>%
  select(Treatment, is.edge, Location, landscapeID) %>%
  distinct() %>%
  filter(is.edge != 0) %>%
  expand_grid(Generation = c(0:120) / 10) %>%
  add_fitted_draws(mod_genetics, re_formula = NA) %>%
  mutate(.value = invlogit(.value)) %>%
  ungroup() %>%
  ggplot() +
  stat_lineribbon(aes(x = Generation, y = .value, fill = Location), .width = 0.95, alpha = 0.5, point_interval = mean_hdi) +
  geom_point(data = data_genetics, aes(x = Generation + is.edge, y = Hexp, bg = Location, col = Location), alpha = 0.6, pch = 21, size = 2) +
  scale_fill_manual(values = edgecorePalette) +
  scale_colour_manual(values = edgecorePalette) +
  scale_y_continuous(name = expression(paste("Genetic diversity  ", italic(H), sep = " "))) +
  scale_x_continuous(name = "Generations since start") +
  facet_wrap(~Treatment) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95")

p2 <- data_genetics %>%
  mutate(landscapeID = landscapeID[1], Generation = 1) %>%
  select(landscapeID, is.edge, Location, Treatment, Generation) %>%
  distinct() %>%
  add_fitted_draws(mod_genetics, nlpar = "logdecay", re_formula = NA) %>%
  mutate(.value = 10^(.value)) %>%
  filter(is.edge != 0) %>%
  ungroup() %>%
  ggplot() +
  stat_eye(aes(x = Location, y = .value, fill = Location), slab_alpha = 0.9, .width=c(0.001,0.95), point_interval = mean_hdi) +
  scale_fill_manual(values = edgecorePalette) +
  facet_wrap(~Treatment) +
  scale_y_continuous(expression(paste("Mean genetic diversity decay rate  ", lambda))) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95") +
  theme(legend.position = "none")

p1 / p2 + plot_annotation(tag_levels = "A") + plot_layout(guides = "collect")
```

```{r summary-stats-genetics}

newdata <- data_genetics %>%
  mutate(landscapeID = landscapeID[1], Generation = 1) %>% # arbitrary, just have to choose one
  select(landscapeID, is.edge, Location, Treatment, Generation) %>%
  filter(is.edge != 0) %>%
  distinct() %>%
  add_fitted_draws(mod_genetics, nlpar = "logdecay", re_formula = NA) %>%
  mutate(.value = (10^(.value)))

## differences in decay between treatments per location
newdata %>%
  group_by(Location) %>%
  compare_levels(.value, by = Treatment, fun = `-`) %>%
  mean_hdi()

## differences in decay between location per treatment
newdata %>%
  group_by(Treatment) %>%
  compare_levels(.value, by = Location, fun = `-`) %>%
  mean_hdi()

## and is the latter difference different among treatments?

newdata %>%
  group_by(Treatment) %>%
  compare_levels(.value, by = Location, fun = `-`) %>%
  ungroup() %>%
  compare_levels(.value, by = Treatment, fun = `-`) %>%
  mean_hdi()
```

### Relationship between *K* and *v*


```{r figure-K-v}
preds_v<-data_popsize %>%
  mutate(Macro = "MacroG2", Generation = 1) %>%
  select(landscapeID, Macro, Treatment, Generation) %>%
  distinct() %>%
  add_fitted_draws(mod_K_v, resp="front", nlpar = "logspeedasym", re_formula = ~(1|landscapeID)) %>% 
  mutate(v=exp(.value)) %>% 
  group_by(landscapeID,Treatment) %>% 
  mean_hdi(v) %>% 
  select(landscapeID,Treatment, v,lower_v=.lower,upper_v=.upper)

preds_K<-data_popsize %>%
  mutate(Macro = "MacroG2", Generation = 1) %>%
  select(landscapeID, Macro, Treatment, Generation) %>%
  distinct() %>%
  add_fitted_draws(mod_K_v, resp="logitPeggsest", re_formula = ~(1|landscapeID)) %>% 
  mutate(K=invlogit(.value)) %>% 
  group_by(landscapeID,Treatment) %>% 
  mean_hdi(K) %>% 
  select(landscapeID,Treatment, K,lower_K=.lower,upper_K=.upper)

p1 <- left_join(preds_v,preds_K) %>% 
  ggplot()+
  geom_segment(aes(x=lower_K*450,xend=upper_K*450,y=v,yend=v),col="grey85")+
  geom_segment(aes(x=K*450,xend=K*450,y=lower_v,yend=upper_v),col="grey85")+
  geom_point(aes(K*450,v,fill=Treatment),pch=21,size=2)+
  scale_y_continuous(expression(paste("predicted asymptotic velocity  ", italic(v))))+
  scale_x_continuous(expression(paste("predicted ", italic(K), " (mean population size in starting patch)")))+
  scale_fill_manual(values=TRTpalette)+
  facet_wrap(~Treatment)+
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95")


cors_K_v=posterior_samples(mod_K_v) %>%
  select(contains("cor_landscapeID__front_logspeedasym")) %>% 
  select(contains("logitPeggsest")) %>% 
  mutate(.iteration = 1:dim(.)[1]) %>% 
  pivot_longer(-.iteration) %>% 
  mutate(Treatment = factor(str_detect(name,"reference"))) %>% 
  mutate(Treatment = fct_recode(Treatment,reference="TRUE", `reduced connectivity`="FALSE")) %>% 
  mutate(Treatment = fct_relevel(Treatment, "reference", after = 0))

p2 <- cors_K_v %>% 
  ggplot()+
  stat_eye(aes(y=value,x=Treatment, fill= Treatment),point_interval=mean_hdi, .width=c(0.001,0.95), slab_alpha = 0.9)+
  geom_hline(yintercept=0,lty=2)+
  scale_y_continuous(expression(paste(italic(K)-italic(v), " correlation")),limits = c(-1,1))+
  scale_x_discrete("")+
  scale_fill_manual(values = TRTpalette)+
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95")

p1/p2 + plot_annotation(tag_levels = "A") + plot_layout(guides = "collect") &
  theme(legend.position = "none")
```


```{r correlation-comparison}

cors_K_v %>% 
  group_by(Treatment) %>% 
  mean_hdi(value)

cors_K_v %>% 
  compare_levels(variable=value,by=Treatment) %>% 
  mean_hdi(value)
```

One can check the result of the bivariate model against a quick and dirty plot of the empirical end speed versus average *K*. Visually, they seem to agree regarding the main result (no correlation in reference, correlation when connectivity is low). 
```{r correlation-check-data}
data_popsize %>% 
  group_by(Treatment,landscapeID,Macro) %>% 
  summarise(speed=max(front)/13,K=mean(Peggs_est)) %>% 
  ggplot()+
  geom_point(aes(K,speed))+
  facet_wrap(~Macro+Treatment)
```

The reason we couldn't simply test directly the correlations on those, and had to go through a bivariate model, is because both *v* and *K* are actually only known with (a lot of) uncertainty, which has to be accounted for (inferences based only on the figure above could have been overconfident).
