---
title: "Supplementary Material for \"Shifts from pulled to pushed range expansions caused by reduction of landscape connectivity\" " 
author: "Maxime Dahirel, Aline Bertin, Marjorie Haond, Aurélie Blin, Eric Lombaert, Vincent Calcagno, Simon Fellous, Ludovic Mailleret, Thibaut Malausa, Elodie Vercken (code by M. Dahirel)"
date:
output: 
  html_document:
    theme: yeti
    toc: TRUE
    toc_float: TRUE
editor_options:
  chunk_output_type: console
bibliography: references.bib
csl: journal-of-animal-ecology.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

## NOTE FOR PEOPLE WHO WOULD WANT TO RE-RUN THE ANALYSES IN THIS FILE:
## most if not all of the models run the 3 main scripts need to have been run and saved for this file to knit correctly
```

```{r packages-loading}
library(arm)

library(adegenet)

library(modelr)
library(RColorBrewer)

### inference
library(rstan)
library(brms)
rstan_options(auto_write = TRUE)
options(mc.cores = 2)


library(tidyverse)

library(tidybayes)
library(bayesplot)

library(patchwork)

library(knitr)
library(kableExtra)

library(cowplot)

library(here)
```

```{r color-palettes}

TRTpalette <- c("#d8b365", "#5ab4ac")
edgecorePalette <- c("#f1a340", "#998ec3")
```

<br/>
<br/> 
**Note: ** The full code for the following document and the analyses it describes, as well as for all analyses described in the main text, is available on GitHub [here](https://github.com/mdahirel/pushed-pulled-2020-dynamics) and Zenodo: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3969988.svg)](https://doi.org/10.5281/zenodo.3969988).

# S1 - Creation of genetic lines

*Trichogramma brassicae* wasps used in the experiment were derived from hybrid populations created in 2013 by mixing parental strains sampled in 24 sites in Western Europe.  These parental strains were initially collected for a project on artificial selection and phenotype amelioration of *T. brassicae* strains for biological control. Isoline populations were then maintained under standard conditions between 2014 and 2016 (18 ± 0.5 °C, 65 ± 10% relative humidity, L:D 18:6), for approximately 20 generations. 

To generate independent experimental replicates with comparable levels of initial genetic diversity, and to allow for evolutionary dynamics, we created three genetic mixes from three isoline populations each (using nine distinct isoline populations in total). We followed the protocol from Fellous *et al.*  [-@fellousCombiningExperimentalEvolution2014] to create mixes with homogeneous genetic background (i.e. similar representation of each of the three ancestral isolines). First, we performed all possible two-by-two crosses between the three isolines. The F1 progeny of each two-by-two cross was then crossed with the third remaining isoline. The F2 individuals from these crosses were then inbred for 2 generations to favour recombination. Individuals from these F4 were then mixed all together in equal proportions to form each final genetic mix. While they did differ from each other, all three mixes had broadly similar levels of genetic diversity at the start of the experiments (**Supplementary Figure S1.1**).

```{r supplementary-figure-1}
raw_genetics <- read_csv(here("data/Trichogramma_genetics.csv"),
  col_types = cols(.default = col_character())
)

## more or less a re-thread of the script used to create the "empirical genetics" dataset in the main code, see there for more details

data_genetics <- raw_genetics %>%
  mutate( ### info on variables is contained in each sample ID
    Generation = str_extract(ID, "G0|G4|G8|G12"),
    Mix = str_extract(ID, "_1P|_2P|_3P"),
    Treatment = str_extract(ID, "PL|PS"),
    Replicate = str_extract(ID, "L_[:digit:]|S_[:digit:]")
  ) %>%
  mutate(
    Generation = as.numeric(str_extract(Generation, "0|4|8|12")),
    Mix = as.numeric(str_extract(Mix, "1|2|3")),
    Replicate = as.numeric(str_extract(Replicate, "[:digit:]"))
  ) %>%
  filter(Generation == 0) %>%  ## we only want diversity at t=0 for this supplementary figure
  mutate(Location = "origin") %>%
  mutate(landscapeID = paste("Mix", Mix, "_Treatment", Treatment, "_Replicate", Replicate, sep = ""))

### STEP 2 isolate the genetics markers
genmat <- df2genind(select(data_genetics, starts_with("TB")), #### all allelic columns start with a "P"
  ncode = 3,
  NA.char = "000",
  ind.names = data_genetics$ID, pop = data_genetics$landscapeID
) # ncode=3 bc 3 characters for one allele

### STEP 3 generate summary of all other columns ; one row = one sampled patch
data_genetics <- data_genetics %>%
  group_by(landscapeID) %>%
  mutate(Nsampled = length(Location)) %>%
  ungroup() %>%
  select(-starts_with("TB"), -ID) %>%
  distinct() %>%
  inner_join(
    tibble(Hexp = Hs(genmat), landscapeID = names(Hs(genmat)))
  )

data_genetics %>%
  ggplot() +
  geom_boxplot(aes(x = factor(Mix), y = Hexp), alpha = 0.2) +
  geom_jitter(aes(x = Mix, y = Hexp), pch = 20, size = 4) +
  scale_y_continuous(name = "Genetic diversity at the start of the experiment (exp. heterozygosity)", limits = c(0.1, 0.45)) +
  scale_x_discrete("Genetic Mix") +
  theme_bw()
```

**Supplementary Figure S1.1** Genetic diversity (multilocus expected heterozygosity) as a function of genetic mix at the start of the experiment. One dot = one experimental landscape. The y axis is scaled to show the full range of genetic diversities observed during the course of the experiment, for reference (see main text)

# S2 - Validating computer estimates of *Trichogramma* population sizes

For analyses asking for population sizes, the proportion of parasitized eggs was estimated based on egg strip photographs using ImageJ [@abramoffImageProcessingImageJ2004] and the `CODICOUNT` plugin [@perezMethodeAnalyseImage2017].  `CODICOUNT` estimates the number of pixels assigned to parasitized host eggs, unparasitized host eggs and background after training. We tested each photograph using 4 macros, each trained on a different set of pictures (from generations 1 2, 3 and 13 respectively) and each potentially having its own systematic bias, combined to better approximate real rates. Proportions of pixels identified as “egg” that were also identified as “parasitized” were used as our estimate of parasitism rate/ population size.

To assess the validity of these automated counts, we manually counted parasitized egg plates from 197 patches (out of 2725 photographed for the experiment) roughly spanning the full range of possible population sizes (human count range: 17 to 443; number of hosts per population ≈ 450). 

```{r data-validate}

raw_dynamics <- read_csv(here("data", "Trichogramma_dynamics.csv"))

data_validate <- raw_dynamics %>%
  mutate(
    Mix = as.numeric(str_sub(Image, 1, 1)),
    Dynamics = str_sub(Image, 2, 3),
    Replicate = as.numeric(str_sub(Image, 4, 4)),
    Patch = as.numeric(str_sub(Image, 6, 7))
  ) %>%
  # no further processing needed; we exploit the fact that chars 6&7 are either digit dot (patchs 0 to 9)
  # or digit-digit (patches 10 and beyond)
  ## as.numeric() resolves both correctly (e.g; "2." and "12" become 2 and 12)
  mutate(landscapeID = paste("Mix", Mix, "_Dynamics", Dynamics, "_Replicate", Replicate, sep = "")) %>%
  mutate(
    Peggs_est = P / (P + H), ## proportion of pixels counted as parasitised (estimated)
    spacetimeID = paste(landscapeID, "_Generation", Generation, "_Patch", Patch, sep = ""), # a unique ID for each replicate x patch x generation combination
    Mix = factor(Mix)
  ) %>%
  group_by(spacetimeID) %>%
  filter(sum(is.na(obs_count) == FALSE) > 0) %>% ### we group by spacetimeID (replicate, patch, time) and we filter out all cases without a human count to validate against
  mutate(Neggs_obs = replace_na(obs_count, 0)) ### there are 4 macro counts but only one human count per spacetimeID (put on the same row as one of the macro counts); the other three are NAs, need to contain filler values (0 here) for the bivariate model to work, which won't be used in the analyses)
# the "filler" approach may not be needed anymore for recent version of brms
```

```{r model-validate}
if (file.exists(here("R_output", "supplementary", "model_S2_computercounts.Rdata"))) {
  load(here("R_output", "supplementary", "model_S2_computercounts.Rdata"))
} else {
  prior_validate <- c(
    set_prior("normal(0,1.5)", class = "Intercept", resp = "Neggsobs"),
    set_prior("normal(0,1)", class = "sd", resp = "Neggsobs"),

    set_prior("normal(0,1.5)", class = "Intercept", resp = "Peggsest"),
    set_prior("normal(0,1)", class = "sd", resp = "Peggsest"), ## half-normal is implied for sd pars in brms
    set_prior("normal(0,1)", nlpar = "invphi", resp = "Peggsest", lb = 0), ## but has to be made explicit for many other types of pars with lb
    set_prior("lkj(2)", class = "cor")
  )

  bf_validate_obs <- bf(Neggs_obs | trials(450) + subset(Neggs_obs > 0) ~ (1 | 1 | spacetimeID), family = binomial)
  bf_validate_estimated <- bf(Peggs_est ~ (1 | 1 | spacetimeID),
    nlf(phi ~ 1 / invphi),
    invphi ~ 1,
    family = Beta(link_phi = "identity")
  )

  mod_validate <- brm(
    mvbf(bf_validate_obs + bf_validate_estimated),
    data = data_validate,
    chains = 4, iter = 22000, warmup = 2000, prior = prior_validate, seed = 42
  )


  save(list = "mod_validate", file = here("R_output", "supplementary", "model_S2_computercounts.Rdata"))
}
```


```{r model-validate-postprocess1}
# latent-scale correlation between human observed and consensus computer values
cor_latent <- posterior_samples(mod_validate) %>%
  select(.value = contains("cor")) %>%
  mean_hdi()

newdata <- filter(data_validate, Macro == "MacroG3") %>% ## selecting a Macro at random, it's just for generating predictions and plots
  ungroup() %>%
  mutate(Neggs_obs = 2, prop_para_pix = 0.2, #again arbitrary and won't be used, we just need the columns to exist for prediction function to work well
         Nhosts = 450) %>%
  select(Nhosts, Peggs_est, Neggs_obs, spacetimeID, Macro) %>%
  distinct()
```


```{r model-validate-postprocess2}

preds_obs <- newdata %>%
  add_fitted_draws(mod_validate, resp = "Neggsobs", value = "human", re_formula = ~ (1 | spacetimeID)) %>%
  ungroup()

## we want "consensus"/"average" computer predictions, so we don't include the Macro effect in the re_formula
preds <- newdata %>%
  add_fitted_draws(mod_validate, resp = "Peggsest", value = "estimated", re_formula = ~ (1 | spacetimeID)) %>%
  ungroup() %>%
  mutate(human = preds_obs$human / 450)
```

```{r model-validate-postprocess3}
##now we have the observed scale predictions, we can estimate the correlation between human and computer on that scale too
## we group by iteration and estimate the correlation for each
cor_obs <- preds %>%
  group_by(.draw) %>%
  nest() %>%
  mutate(.value = map(data, ~ cor.test(.$estimated, .$human)$est)) %>%
  unnest(.value) %>%
  select(.draw, .value) %>%
  ungroup() %>%
  mean_hdi()

##we also need to look at a potential bias: do computer estimates systematically under or over estimate?

diff_obs_est <- preds %>%
  mutate(diff = human - estimated) %>%
  group_by(.draw) %>%
  summarise(diff = 100 * mean(diff)) %>%
  mean_hdi()
```

We then used a bivariate generalized linear mixed model approach to compare computer estimates and human counts, with a Beta family used for the former and a binomial distribution for the latter. Both models contained a fixed-effect intercept as well as random intercepts of population/patch identity, which were correlated. This approach accounts for the data structure and the fact both human- and computer-derived counts are likely estimated with error [@perezMethodeAnalyseImage2017]. It allows us to estimate the correlation between human counts and “consensus” computer counts obtained from pooling information from all macros. 

Estimated and human-observed parasitism rates were highly correlated both on the latent logit scale (*r*= `r round(cor_latent$.value,2)` [`r round(cor_latent$.lower,2)`, `r round(cor_latent$.upper,2)`]) and on the observed scale (*r* = `r round(cor_obs$.value,2)` [`r round(cor_obs$.lower,2)`, `r round(cor_obs$.upper,2)`]). There was also no evidence of bias (predicted mean difference between "human" and "computer" parasitism rates, in % of hosts per patch = `r round(diff_obs_est$diff,2)`% [`r round(diff_obs_est$.lower,2)`, `r round(diff_obs_est$.upper,2)`])

We then refitted this model, this time adding a fixed effect of the macro in the "computer estimates" submodel, to determine whether macros presented systematic biases. We found that the overall absence of bias of the "consensus" estimates (see above) actually resulted from the majority of macros slightly underpredicting human-observed parasitism rates while one consistently overpredicted them (**Supplementary Figure S2.1**).

```{r model-validate2}
if (file.exists(here("R_output", "supplementary", "model_S2_computercountsbymacro.Rdata"))) {
  load(here("R_output", "supplementary", "model_S2_computercountsbymacro.Rdata"))
} else {
  prior_validate <- c(
    set_prior("normal(0,1.5)", class = "Intercept", resp = "Neggsobs"),
    set_prior("normal(0,1)", class = "sd", resp = "Neggsobs"),

    set_prior("normal(0,1.5)", class = "b", resp = "Peggsest"),
    set_prior("normal(0,1)", class = "sd", resp = "Peggsest"), ## half-normal is implied for sd pars in brms
    set_prior("normal(0,1)", nlpar = "invphi", resp = "Peggsest", lb = 0), ## but has to be made explicit for many other types of pars
    set_prior("lkj(2)", class = "cor")
  )

  bf_validate_obs <- bf(Neggs_obs | trials(450) + subset(Neggs_obs > 0) ~ (1 | 1 | spacetimeID), family = binomial)
  bf_validate_estimated <- bf(Peggs_est ~ 0 + Macro + (1 | 1 | spacetimeID),
    nlf(phi ~ 1 / invphi),
    invphi ~ 1,
    family = Beta(link_phi = "identity")
  )

  mod_validate2 <- brm(
    mvbf(bf_validate_obs + bf_validate_estimated),
    data = data_validate,
    chains = 4, iter = 22000, warmup = 2000, prior = prior_validate, seed = 42
  )

  save(list = "mod_validate2", file = here("R_output", "supplementary", "model_S2_computercountsbymacro.Rdata"))
}

obs <- data_validate %>%
  ungroup() %>%
  mutate(spacetimeID = spacetimeID[1], Neggs_obs = 1) %>%
  select(spacetimeID, Macro, Neggs_obs) %>%
  distinct() %>%
  add_fitted_draws(mod_validate2, resp = "Neggsobs", re_formula = NA) %>%
  mean_hdi()

data_validate %>%
  ungroup() %>%
  mutate(spacetimeID = spacetimeID[1], Neggs_obs = 1) %>%
  select(spacetimeID, Macro, Neggs_obs) %>%
  distinct() %>%
  add_fitted_draws(mod_validate2, resp = "Peggsest", re_formula = NA) %>%
  ggplot() +
  geom_hline(aes(yintercept = obs$.value[1] / 450), size = 1.2) +
  geom_hline(aes(yintercept = obs$.lower[1] / 450), lty = 2) +
  geom_hline(aes(yintercept = obs$.upper[1] / 450), lty = 2) +
  stat_eye(aes(Macro, .value), .width=c(0.01,0.95)) +
  scale_y_continuous("Parasitism rate", limits = c(0.25, 0.75)) +
  theme_bw()
```

**Supplementary Figure S2.1** Posterior mean estimated parasitism rate, by computer macro, for the 197 plates used to compare human and computer counts. Horizontal lines denote the mean (bold line) and 95% credible interval (dotted lines) for the posterior mean parasitism rate based on human counts.

# S3 – Validation of the experimental design

To determine whether our experimental reduction of structural connectivity did limit individual movement (i.e. functional connectivity), we used data from the first generation of testing, i.e. the only time the patch of origin of all parents can be known with certainty. 

We used parasitism rates to calculate for each landscape × macro the average egg location (in patches from release) and used it as a proxy of dispersal distance (works because dispersal can be define as more or less parent-offspring distance). We analysed this distance using a Beta generalised linear mixed model (dividing it by 4, the maximal possible distance, to ensure it stayed between 0 and 1). The model included a fixed effect of treatment, as well as a random effect of macro (random intercept) to account for uncertainty in our estimates of parasitism and distances, more specifically for macro-level systematic biases.

As expected, we found that released wasps did lay their eggs closer from release sites in landscapes with reduced connectivity compared to reference landscapes (**Supplementary Figure S3.1**).

```{r data-G0}
raw_dynamics <- read_csv(here("data", "Trichogramma_dynamics.csv"))

data_G0 <- raw_dynamics %>%
  mutate(
    Mix = as.numeric(str_sub(Image, 1, 1)),
    Treatment = str_sub(Image, 2, 3),
    Replicate = as.numeric(str_sub(Image, 4, 4)),
    Patch = as.numeric(str_sub(Image, 6, 7))
  ) %>%
  # no further processing needed; we exploit the fact that chars 6&7 are either digit dot (patchs 0 to 9)
  # or digit-digit (patches 10 and beyond)
  ## as.numeric() resolves both correctly (e.g; "2." and "12" become 2 and 12)
  mutate(landscapeID = paste("Mix", Mix, "_Treatment", Treatment, "_Replicate", Replicate, sep = "")) %>% # a unique replicate ID
  mutate(
    Peggs_est = P / (P + H), ## proportion of pixels counted as parasitised (estimated)
    spacetimeID = paste(landscapeID, "_Generation", Generation, "_Patch", Patch, sep = ""), # a unique ID for each replicate x patch x generation combination
    Mix = factor(Mix)
  ) %>%
  mutate(Treatment = fct_recode(Treatment, `reference` = "PL", `reduced connectivity` = "PS")) %>% 
  filter(Generation == 1 & Patch <= 4) %>%
  ## only patches 0 to 4 are available at start (adding "Patch <=4" above is not necessary, but it makes it explicit)
  select(landscapeID, Mix, Treatment, Patch, Peggs_est, Macro) %>%
  ungroup() %>%
  pivot_wider(., names_from = "Patch", values_from = c("Peggs_est"), names_prefix = "P") %>%
  filter(is.na(P0) == FALSE) %>% ## remove one row with the one macro with missing info for "resident" eggs (can't estimate dispersal)
  mutate(P1 = replace_na(P1, 0)) %>%
  mutate(P2 = replace_na(P2, 0)) %>%
  mutate(P3 = replace_na(P3, 0)) %>%
  mutate(P4 = replace_na(P4, 0)) %>%
  mutate(Pall = (P0 + P1 + P2 + P3 + P4)) %>%
  mutate(
    distmean = (1 * P1 + 2 * P2 + 3 * P3 + 4 * P4) / Pall) %>% ## mean distance from release
  mutate(jitteredTRT = jitter(as.numeric(factor(Treatment)))) %>% ## just for pretty plotting
  group_by(landscapeID) %>%
  mutate(jitteredTRT = mean(jitteredTRT)) %>% ## same: ensures same jitter for same measure from different macros
  ungroup()
```


```{r model-g0}

if (file.exists(here("R_output", "supplementary", "model_S3_initialdispersal.Rdata"))) {
  load(here("R_output", "supplementary", "model_S3_initialdispersal.Rdata"))
} else {
  mod_G0 <- brm(bf(
    distmean / 4 ~ 0 + Treatment + (1 | Macro),
    ### divided by 4 because it's the maximal possible distance possible at G0
    nlf(phi ~ 1 / invphi),
    invphi ~ 1
  ),
  data = data_G0, family = Beta(link_phi = "identity"),
  iter = 6000, chains = 4,
  prior = c(
    set_prior("normal(0,1.5)", class = "b"),
    set_prior("normal(0,1)", class = "sd"),
    set_prior("normal(0,1)", nlpar = "invphi", lb = 0)
  ),
  control = list(adapt_delta = 0.99,max_treedepth=15), seed = 42
  )

  save(list = "mod_G0", file = here("R_output", "supplementary", "model_S3_initialdispersal.Rdata"))
}
```

```{r figure-G0}

newdata <- data_G0 %>%
  mutate(Macro = Macro[1]) %>% # it's just a placeholder, we plot the posterior for the "true" (grand) mean distance, without random effects
  select(Macro, Treatment) %>%
  distinct()

## these averages are just indicative and for plotting purposes
data_G0_avg <- data_G0 %>%
  group_by(landscapeID, Treatment) %>%
  summarise(
    distmean = mean(distmean),
    jitteredTRT = mean(jitteredTRT)
  ) %>%
  ungroup()

## the main plot
p1 <- newdata %>%
  add_fitted_draws(mod_G0, re_formula = NA) %>%
  ggplot() +
  stat_eye(aes(x = Treatment, y = .value * 4, fill = Treatment), 
           .width = c(0.01, 0.95), slab_alpha = 0.9, point_interval = mean_hdi) +
  ## we put both observed points (by macros) and the indicative averages for each each landscape
  geom_point(data = data_G0, aes(x = jitteredTRT, y = distmean, col = Treatment), fill = "white", pch = 21, alpha = 0.8) +
  geom_point(data = data_G0_avg, aes(x = jitteredTRT, y = distmean, fill = Treatment), pch = 21, size = 2) +
  scale_fill_manual(values = TRTpalette) +
  scale_colour_manual(values = TRTpalette) +
  scale_x_discrete("") +
  scale_y_continuous("Mean egg-laying distance from release site (patches)", limits = c(-0.2, 2.5)) +
  theme_bw()

## a subplot showing the difference between treatments
p2 <- newdata %>%
  add_fitted_draws(mod_G0, re_formula = NA) %>%
  ungroup() %>%
  compare_levels(variable = .value, by = Treatment) %>%
  ggplot() +
  stat_eye(aes(x = Treatment, y = .value * 4),
           .width = c(0.01, 0.95), fill = "grey", point_interval = mean_hdi) +
  scale_x_discrete("", labels = "") +
  scale_y_continuous("Difference between treatments",
    limits = c(-0.2, 2.5) - 4 * invlogit(fixef(mod_G0)["Treatmentreference", "Estimate"])
  ) + ## so the "difference" subplot is aligned with the main
  geom_hline(yintercept = 0, lty = 2) +
  theme_bw()

p1 + p2 + plot_layout(guides = "collect", widths = c(4, 1)) & theme_bw() &
  theme(legend.position = "none")

```

**Supplementary Figure S3.1.** Left: Average egg-laying distance from release patch as a function of treatment. Colored areas: posterior distributions of the averages; black dots and segments: posterior mean and 95% credible intervals; empty colored dots: estimated values for each macro; full colored dots: averages across macros for each replicate. Right: posterior difference between the two experimental treatments.

# S4 - Microsatellite genotyping, detailed methods

## S4.1 - Design of the microsatellite markers and multiplex PCR assay

Microsatellite DNA libraries were produced following the method described in Malausa *et al.* [-@malausaHighthroughputMicrosatelliteIsolation2011]. This method consists of (i) the isolation of DNA fragments containing microsatellite motifs by multiplex microsatellite enrichment (obtained via hybridisation to biotin-labelled oligonucleotides with the motifs (AG)~10~, (AC)~10~, (AAC)~8~, (AGG)~8~, (ACG)~8~, (AAG)~8~, (ACAT)~6~ and (ATCT)~6~) and (ii) the pyrosequencing of the fragments (454 GS-FLX Titanium). This protocol was applied to a sample containing DNA extracted from about 100 *Trichogramma brassicae* individuals.

The obtained DNA dataset was analyzed and primers for microsatellite amplification were designed using the QDD program [@megleczQDDUserfriendlyProgram2010], version 2.1. The default QDD parameters were used, except for: (i) the minimum percentage similarity of sequences used for the construction of consensus sequences was 90%, (ii) the proportion of sequences that must have the same base on the aligned site to accept it as a consensus was 0.66, (iii) the minimum length of PCR product for primer design was 80bp, (iv) the maximum length of PCR product for primer design was 500, (v) the maximum length of a primer was 32, (vi) the maximum acceptable difference between the melting temperatures of primers was 4°C.

Nineteen microsatellite markers were developed by testing and multiplexing part of the PCR primers selected after the QDD analysis. The main criteria for microsatellites sequences selection and primers design used were (i) the motif of the microsatellite they target, to obtain a balanced frequency of motifs, (ii) microsatellites with at least eight repeats, (iii) the size of the expected PCR products (we selected primers amplifying markers homogeneously distributed in terms of size within the range 80 bp - 500 bp).

## S4.2 - Genotyping and microsatellites description  

All sequenced *T. brassicae* wasps were stored in 70% ethanol before DNA extraction. DNA was extracted from each individual wasp, either with the prepGem Insect DNA Extraction kit from Zygem (extraction volume of 15µL per individual, using 0.375µL of prepGem enzyme; samples were placed in a thermocycler for 2 hours at 75°C and 5 minutes at 95°C), or with the Quick Extract DNA Extraction Solution from Lucigen (extraction volume of 15µL per individual; samples were placed in a thermocycler for 10 minutes at 65°C and 2 minutes at 98°C). All DNA extracts were stored at -20°C.  

For microsatellite amplification, 2µl of genomic DNA were used within a 10µL final PCR reaction consisting of 5µL of the QIAGEN PCR multiplex solution, 1µL of the primer mix of the 19 primers reverse and forward (1µM each), and water. PCR conditions were as followed: initial denaturation at 95°C for 15 min; 30 cycles of denaturation (94°C, 30s), annealing (60°C, 90s) and elongation (72°C, 60s); final extension at 60°C for 30 min.
For each individual, 1.5µL of the PCR product was mixed with 9.8µL of a mix obtained from 1mL HiDi formamide and 20µL of 500 LIZ Size Standard (Applied Biosystems). Products were then electrophoresed using an ABI PRISM 3130XL sequencer (Applied Biosystems). Finally, genotypes were scored using Gene Marker version 1.75 (SoftGenetics).

All loci are polymorphic when looking at the entire dataset (**Supplementary Table S4.1**). Information on each marker, including allelic richness over the whole set of genotyped individuals, is presented **Supplementary Table S4.1**. Information about genetic diversity and whether alleles frequencies followed the Hardy-Weinberg equilibrium **at the start of the experiment** is presented Supplementary Table S4.2. 

Summary data **Table S4.2** confirm that all 3 source strains (genetic mixes) are polymorphic and diverse at the majority of the loci chosen, and that only a limited number of loci are polymorphic in 1 strain and fixed in the other 2. One locus has H0(t = 0) = 0 for all strains. However, we note that all loci do present variation in later generation samples (a prerequisite for keeping the locus for the analysis; data not shown here). So, barring multiple mutations, this seemingly fixed locus must simply represent sampling error at t = 0.


**Supplementary Table S4.1**: Primer pairs used for the PCR set of the multiplex panel. For each of the 19 loci, the table includes: the repeat motifs in the sequence used to design primers, sequence and fluorescent dye label used for each primer, the observed number of alleles and the allelic size range. 

```{r table-microsat1}
raw_genetics <- read_csv(here("data/Trichogramma_genetics.csv"),
  col_types = cols(.default = col_character())
)

data_genetics <- raw_genetics %>%
  mutate( ### info on variables is contained in each sample ID
    Generation = str_extract(ID, "G0|G4|G8|G12"),
    Mix = str_extract(ID, "_1P|_2P|_3P")
  ) %>%
  mutate(
    Generation = as.numeric(str_extract(Generation, "0|4|8|12")),
    Mix = as.numeric(str_extract(Mix, "1|2|3"))
  )

genmat <- df2genind(select(data_genetics, starts_with("TB")), #### all allelic columns start with a "P"
  ncode = 3,
  NA.char = "000", ## missing alleles
  ind.names = data_genetics$ID, pop = data_genetics$Mix
) # ncode=3 bc 3 characters for one allele


test <- enframe(genmat@all.names) %>%
  unnest(cols = value) %>%
  mutate(value = as.numeric(value)) %>%
  filter(value > 0) %>% ## remove missing alleles (scored as 0s)
  group_by(name) %>%
  summarise(min = min(value), max = max(value)) %>%
  mutate(range = paste(min, "-", max)) %>%
  left_join(tibble(nAll = nAll(genmat), name = names(nAll(genmat)))) %>%
  select(Locus = name, `number of alleles` = nAll, `Size range (bp)` = range)

read_csv(here("data", "Trichogramma_microsatellite_description.csv")) %>%
  rename(Locus = "locus", `Repeat motif` = "motif", Forward = "forward_primer", Reverse = "reverse_primer", `Fluorescent dye` = "dye") %>%
  left_join(test) %>%
  kable(format = "html") %>%
  kable_styling() %>%
  add_header_above(c(" " = 2, "Primer sequences (5'—3')" = 2, " " = 3)) %>%
  collapse_rows(5, valign = "top") ##
```

**Supplementary Table S4.2**: Population genetics statistics **at the start of the experiment** (Generation 0 samples). At each locus described **Supplementary Table S4.1**, the number of individuals successfully genotyped (*N*, excluding missing alleles),the observed heterozygosity (*H~O~*), the expected heterozygosity (*H~E~*, @neiAnalysisGeneDiversity1973) and the *p*-value for the exact test of Hardy–Weinberg equilibrium were computed separately for each of the 3 genetic mixes used (Mix1, Mix2, Mix3; See Supplementary Material S1). Statistics were computed using the `adegenet` [@jombartAdegenetPackageMultivariate2008] and `pegas` [@paradisPegasPackagePopulation2010] R packages. Note that all loci were found to be polymorphic when analysing the whole set of wasps used in the experiment (See **Supplementary Table S4.1**).

```{r table-microsat2}

data_genetics <- data_genetics %>%
  filter(Generation == 0)

genmat <- df2genind(select(data_genetics, starts_with("TB")), #### all allelic columns start with a "P"
  ncode = 3,
  NA.char = "000", ## missing alleles
  ind.names = data_genetics$ID, pop = data_genetics$Mix
) # ncode=3 bc 3 characters for one allele

seppop(genmat) %>% #we split by Mix, and for each mix we obtain some popgen metrics
  map(
    .x = .,
    .f = ~ tibble(
      Locus = locNames(.x),
      N = seploc(.x) %>% ### a very convoluted way to get N because nInd(.x) doesn't account for NAs
        map(
          .x = ., ### so for each locus
          .f = ~ tab(.x) %>% ### we get the table of allelic frequencies
            rowSums() %>% ### we sum by individuals
            na.omit() %>% ### we remove the NAs
            length() ### we count
        ) %>%
        unlist(),
      Ho = summary(.x)$Hobs %>% round(2),
      He = summary(.x)$Hexp %>% round(2),
      HW = pegas::hw.test(.x)[, "Pr.exact"] %>% round(2)
    )
  ) %>%
  enframe() %>%
  unnest(cols = c(value)) %>%
  rename(Mix = "name") %>%
  mutate(HW = as.character(HW)) %>%
  mutate(HW = ifelse(Ho == 0 & He == 0, "--", HW)) %>%  #if no diversity *in sample*, no valid Hardy-Weinberg equilibrium test
  group_by(Locus) %>%
  summarise(`*N*` = paste(N, collapse = ", "), `*H~O~*` = paste(Ho, collapse = ", "), `*H~E~*` = paste(He, collapse = ", "), `HWE *p*-value` = paste(HW, collapse = ", ")) %>%
  kable(format = "simple")
```


# S5 - Detailed description of models

We here describe the full structure of the models presented in the main text and supplementary materials, as well as associated prior choices. We try to follow throughout the same notation conventions as McElreath [-@mcelreathStatisticalRethinkingBayesian2020]. Unless noted, variable names and indices are reset from one model to the next, for simplicity, but similar names always refer to similar types of variables (fixed effects/random effects/correlations...). All Beta models descriptions use the (mean, precision) parametrisation of the Beta distribution. We use the $\mathrm{Half\mbox{-}Normal}(0,\sigma)$ notation to denote a half-normal distribution based on a $\mathrm{Normal}(0,\sigma)$ distribution.

## S5.1 - Genetic diversity, experimental data

We can describe the genetic diversity (expected heterozygosity) $H_{x,i,t}$ of a patch in replicate $i$, with $x$ denoting the location of that patch (0 for core patches, 1 for edge/front patches) and $t$ the number of generations since release, the following way:

$$ 
\mathrm{logit}(H_{x,i,t}) \sim \mathrm{StudentT}(\mathrm{logit}(\mu_{x,i,t}) , \sigma_{d} , \nu ),
$$
where $\mu_{x,i,t}$ is the mean genetic diversity, $\sigma_{d}$ the distribution scale parameter and $\nu$ the number of degrees of freedom. 

Based on theory, we expect average genetic diversity to decline exponentially with time: 

$$ 
\mu_{x,i,t} =   \mu_{i,t=0} \times  \exp(-\lambda_{x,i} \times t).
$$

The two parameters $\mu_{i,t=0}$ (initial diversity) and  $\lambda_{x,i}$ (rate of decline) depend on replicate, treatment (reference or reduced connectivity) and location (core $x = 0$ or edge $x = 1$) as follows:

$$
\mathrm{logit}(\mu_{i,t=0}) = \beta_{0} + \alpha_{i}, \\
\log_{10}(\lambda_{x,i}) = \beta_{1[\text{TREATMENT}[i]]}+\beta_{2[\text{TREATMENT[i]}]}(x-0.5) + \gamma_{i} + \zeta_{i}(x-0.5)
$$
(with $\mathrm{logit}$ and $\log_{10}$ transformations here to ensure both parameters stay within bounds). 

Initial diversity is thus independent of treatment and location, and only depends on replicate identity through a random effect $\alpha_{i}$, while the rate of decline $\lambda$ depends on treatment, location and their interaction. (Note the centring of $x$ in the formula, and that $x$ is set to 0.5 at $t$ = 0, so that the effect of location on $\lambda$ cancels out at the start of the experiment, when "core" and "edge" are not distinct). In addition, both the average decline rate and the edge-core difference depend on replicate, which is accounted for through the random effect parameters $\gamma_{i}$ and $\zeta_{i}$ respectively.

The random effects are distributed as follows: 

$$
\begin{bmatrix}
\alpha_{i} \\
\gamma_{i} \\
\zeta_{i} \\
\end{bmatrix} \sim 
\mathrm{MVNormal}(
\begin{bmatrix}
0\\
0\\
0\\
\end{bmatrix},\boldsymbol{\Omega}),
$$
with $\boldsymbol{\Omega}$ the covariance matrix:

$$
\boldsymbol{\Omega} = 
\begin{bmatrix}
\sigma_{\alpha} & 0 & 0 \\
0 & \sigma_{\gamma} & 0 \\
0 & 0 & \sigma_{\zeta} \\
\end{bmatrix} 
\times \boldsymbol{\mathrm{R}} \times
\begin{bmatrix}
\sigma_{\alpha} & 0 & 0 \\
0 & \sigma_{\gamma} & 0 \\
0 & 0 & \sigma_{\zeta} \\
\end{bmatrix},
$$
where $\sigma_{\alpha}$, $\sigma_{\gamma}$ and $\sigma_{\zeta}$ are the random effect standard deviations for each parameter, and $\boldsymbol{\mathrm{R}}$ the corresponding correlation matrix.

We used weakly informative priors mostly following McElreath [-@mcelreathStatisticalRethinkingBayesian2020]. For the fixed intercept of the initial diversity $\beta_{0}$, which corresponds to the logit of a proportion, we used a $\mathrm{Normal}(0,1.5)$, which gives a relatively flat prior when converted back to proportions. For all other fixed effects parameters $\beta_{j|j > 0}$, we used a $\mathrm{Normal}(0, 1)$ prior (note that results are overall insensitive to fixing both standard deviations to 1 or to 1.5). All standard deviation parameters $\sigma$ (including the distributional standard deviation $\sigma_{d}$) were attributed the same $\mathrm{Half\mbox{-}Normal}(0,1)$ prior. For the random effect correlation matrix $\boldsymbol{\mathrm{R}}$ we used a $\mathrm{LKJCorr}(2)$ prior, while we used a $\mathrm{Gamma}(2,0.1)$ for the degrees of freedom $\nu$, based on Stan developers recommendations (https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations).

An alternative model can be written, where $H_{x,i,t} \sim \mathrm{Beta}(\mu_{x,i,t}, \phi)$, but it has a lower predictive performance (see Methods in the main text, and details in linked code (main script 1)). Following recommendations for weakly informative priors (https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations), we use there a $\mathrm{Half\mbox{-}Normal}(0,1)$ prior on $1/\phi$ (all other parameters and priors are as described above).

## S5.2 - Genetic diversity, simulated data

In our simulations, it is not possible to analyse genetic diversity using the model(s) described in S5.1, in large part because simulated diversity data contains many zeroes, which means models using both logit transformations and Beta distributions are inappropriate.

As an alternative, we can use the model proposed by Gandhi *et al.* [-@gandhiCooperationMitigatesDiversity2019] in which, for a given treatment and location combination $j$ at a given time $t$ (in generations from release), the expected among-replicate variance in the frequencies of either one of the two alleles $V_{j,t}$ can be described this way:

$$ V_{j,t} \sim \mathrm{Beta}(\mu_{j,t}, \phi),$$

$$ \mu_{j,t} =   V_{\max} \times  (1 - \exp(-\lambda_{j} \times t)),$$ 

where $V_{max}$ is both the asymptotic variance (once all patches have reached fixation) and the product of initial allele frequencies (and so only depends on the initial allelic distribution, not on treatment or patch type), and $\lambda$ a rate of decay of genetic diversity, which varies between treatments and locations (core vs. edge) as in the "experimental" model.

We put the same priors on $\log_{10}(\lambda)$ and $1/\phi$  as in the experimental models ($\mathrm{Normal}(0, 1)$ and $\mathrm{Half\mbox{-}Normal}(0, 1)$, respectively), for the same reasons. We put a stronger, informative prior on $\mathrm{logit}(V_{max})$ :

$$ \mathrm{logit}(V_{max}) \sim \mathrm{Normal}(\mathrm{logit}(0.25), 0.5), $$
as the expected asymptotic among-replicate variance is 0.25 for the case of a randomly distributed and randomly fixating locus with two alleles ($p(1-p)$ with $p$ = 0.5).

## S5.3 - Front velocity, experimental and simulated data

In both experimental and simulation data, the location $X_{i,t}$ of the expansion front of the $i$th replicate after $t$ generations can be modelled as follows:

$$ X_{i,t} \sim \mathrm{Log\mbox{-}Normal}(\log (v_{i,t} \times t), \sigma_{d}),$$

where $v_{i,t}$ denotes the expansion speed over the $t$ generations since release, and $\sigma_{d}$ is the residual standard deviation of the log-distances.

The expansion speed $v_{i,t}$ can then be modelled as follows:

$$v_{i,t} = v_{i,t \to \infty} + (v_{i,t=1} - v_{i,t \to \infty}) \times \exp(-\lambda_{i} \times (t -1)),$$

that is, moving from an initial speed $v_{i,t=1}$ to an equilibrium speed $v_{i,t \to \infty}$, with the rate of exponential "decay" to the asymptotic speed being $\lambda_{i}$.
  
In the experiment, all three parameters depend on treatment, and on replicate identity:

$$
\log(v_{i,t=1}) = \log(v_{\text{TREATMENT}[i], t=1}) + \alpha_{i}, \\
\log(v_{i,t \to \infty}) = \log(v_{\text{TREATMENT}[i], t \to \infty}) + \gamma_{i},\\
\log_{10}(\lambda_{i}) = \log_{10}(\lambda_{\text{TREATMENT}[i]}) + \zeta_{i}.
$$

In simulated data, we fixed $v_{i,t=1} = 1$ (see main text for rationale), we logit-transformed $v_{i,t \to \infty}$ rather than log-transforming it (because speeds were constrained between 0 and 1):

$$
\mathrm{logit}(v_{i,t \to \infty}) = \mathrm{logit}(v_{\text{TREATMENT}[i], t \to \infty}) + \gamma_{i},
$$
and we rescaled $(t -1)$ to $(t - 1) /10$ (so expressed elapsed time in 10s of generations), to facilitate convergence while keeping the same weakly informative priors. The model is otherwise unchanged.

In both simulated and experimental data, the random effects $\alpha_{i}$, $\gamma_{i}$ and $\zeta_{i}$ are distributed as follows: 

$$
\begin{bmatrix}
\alpha_{i} \\
\gamma_{i} \\
\zeta_{i} \\
\end{bmatrix} \sim 
\mathrm{MVNormal}(
\begin{bmatrix}
0\\
0\\
0\\
\end{bmatrix},\boldsymbol{\Omega}),
$$

with $\boldsymbol{\Omega}$ the covariance matrix:

$$
\boldsymbol{\Omega} = 
\begin{bmatrix}
\sigma_{\alpha} & 0 & 0 \\
0 & \sigma_{\gamma} & 0 \\
0 & 0 & \sigma_{\zeta} \\
\end{bmatrix} 
\times \boldsymbol{\mathrm{R}} \times
\begin{bmatrix}
\sigma_{\alpha} & 0 & 0 \\
0 & \sigma_{\gamma} & 0 \\
0 & 0 & \sigma_{\zeta} \\
\end{bmatrix},
$$

where $\sigma_{\alpha}$, $\sigma_{\gamma}$ and $\sigma_{\zeta}$ are the random effect standard deviations for each parameter, and $\boldsymbol{\mathrm{R}}$ the corresponding correlation matrix.

We used $\mathrm{Normal}(0,1)$ priors for all fixed effects parameters (except $\mathrm{logit}(v_{\text{TREATMENT}[i], t \to \infty})$ for simulated data, $\mathrm{Normal}(0,1.5)$). We used  $\mathrm{Half\mbox{-}Normal}(0,1)$ priors for all standard deviations $\sigma$ and a LKJ prior $\mathrm{LKJcorr}(2)$ for the correlation matrix $\boldsymbol{\mathrm{R}}$

Alternatively, one can assume (based on theory) that speed converges to the asymptote following an power law, rather than an exponential:

$$
v_{i,t} = v_{i,t \to \infty} + (v_{i,t=1} - v_{i,t \to \infty}) \times t^{-\lambda_{i}},
$$

(with all other elements of the models remaining otherwise unchanged). However, model comparison (see code) show this performs much worse than the exponential in the context of the simulated data.

## S5.4 - Population size in core patch, experimental data

We first assumed the parasitism rate in the release patch $P_{i,t,m}$ observed by macro $m$ in replicate $i$ after $t$ generations can be modelled using a Beta model as follows:

$$ 
P_{i,t,m} \sim \mathrm{Beta}(K_{i,m}, \phi), \\
\mathrm{logit}(K_{i,m}) = \beta_{\text{TREATMENT}[i]} +\eta_{i} + \theta_{m},\\
\eta_{i} \sim \mathrm{Normal}(0,\sigma_{\eta}), \\
\theta_{m} \sim \mathrm{Normal}(0,\sigma_{\theta}),
$$
where $K$ are the mean carrying capacities, $\eta$ denote random effects of replicate and $\theta$ random effects accounting for systematic between-macro differences. Priors were the same as in previous Beta models, that is a $\mathrm{Normal}(0,1.5)$ for $\beta$s, and a $\mathrm{Half\mbox{-}Normal}(0,1)$ for both random effect standard deviations $\sigma$ and for $1/\phi$.

However, posterior checks revealed this model predicted more variability than was in the data, like for genetic experimental data. So, like with genetic experimental data, we shifted to a Student model on logit-transformed data:

$$ 
\mathrm{logit}(P_{i,t,m}) \sim \mathrm{StudentT}(\mathrm{logit}(K_{i,m}), \sigma_{d} , \nu),
$$
with everything else unchanged. Priors are as in the previous model, so a $\mathrm{Normal}(0,1.5)$ for $\beta$s, and a $\mathrm{Half\mbox{-}Normal}(0,1)$ for random effect standard deviations $\sigma$. We again used a $\mathrm{Gamma}(2,0.1)$ prior for the Student-specific $\nu$.

## S5.5 - Correlation between $K_{i}$ and $v_{i,t \to \infty}$, experimental data

To analyse the among-replicate correlation between the asymptotic speed $v_{i,t \to \infty}$ and the carrying capacity $K_{i}$, we simply combine the two univariate models described above for front location (**S5.3**) and population size (**S5.4**). We simply adjust the replicate-level random effect variance-covariance matrix to (1) link the two model (2) make it treatment-specific, in order to obtain treatment-specific correlations ($i$ denotes the replicate, $j$ the treatment, and parameter names are as in **S5.3** and **S5.4**):

$$
\begin{bmatrix}
\alpha_{i,j} \\
\gamma_{i,j} \\
\zeta_{i,j} \\
\eta_{i,j} \\
\end{bmatrix} \sim 
\mathrm{MVNormal}(
\begin{bmatrix}
0\\
0\\
0\\
0\\
\end{bmatrix},\boldsymbol{\Omega}_{j}),
$$

with $\boldsymbol{\Omega}_{j}$ the now treatment-specific covariance matrix and $\boldsymbol{\mathrm{R}}_{j}$ the corresponding correlation matrix:

$$
\boldsymbol{\Omega}_{j} = 
\begin{bmatrix}
\sigma_{\alpha[j]} & 0 & 0 & 0 \\
0 & \sigma_{\gamma[j]} & 0 & 0 \\
0 & 0 & \sigma_{\zeta[j]} & 0 \\
0 & 0 & 0 & \sigma_{\eta[j]} \\
\end{bmatrix} 
\times \boldsymbol{\mathrm{R}}_{j} \times
\begin{bmatrix}
\sigma_{\alpha[j]} & 0 & 0 & 0 \\
0 & \sigma_{\gamma[j]} & 0 & 0 \\
0 & 0 & \sigma_{\zeta[j]} & 0 \\
0 & 0 & 0 & \sigma_{\eta[j]} \\
\end{bmatrix}. 
$$
All other parameters and all priors are as in the corresponding univariate models.

## S5.6 - validation of computer estimates of population sizes (Supplementary Material S2)

To compare computer estimates of parasitism rate $P_{i,m}$ with human counts of parasitised eggs $n_{i}$ (where $i$ is a given patch and $m$ is the estimating computer macro), we used the following bivariate mixed model:

$$
n_{i} \sim \mathrm{Binomial}(N = 450, p_{i}), \\
P_{i,m} \sim \mathrm{Beta}(\mu_{i}, \phi), \\
\mathrm{logit}(p_{i}) = \beta_{0} + \alpha_{i} ,\\
\mathrm{logit}(\mu_{i}) = \beta_{1} + \gamma_{i},
$$
in which the patch-level random effects $\alpha$ and $\gamma$ are correlated and distributed as follows:

$$
\begin{bmatrix}
\alpha_{i} \\
\gamma_{i} \\
\end{bmatrix} \sim 
\mathrm{MVNormal}(
\begin{bmatrix}
0\\
0\\
\end{bmatrix},\boldsymbol{\Omega}), \\
\boldsymbol{\Omega} = 
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\gamma} \\
\end{bmatrix} 
\times \boldsymbol{\mathrm{R}} \times
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\gamma} \\
\end{bmatrix},
$$
where $\Omega$ and $\boldsymbol{\mathrm{R}}$ again refer the the covariance and correlation matrices, respectively. As in similar models described above, we use a $\mathrm{Normal}(0,1.5)$ for fixed effect ($\beta$) parameters, a $\mathrm{Half\mbox{-}Normal}(0,1)$ prior for standard deviations $\sigma$ and for $1/\phi$, and a $\mathrm{LKJCorr}(2)$ prior for the correlation matrix $\boldsymbol{\mathrm{R}}$. 

We ran a second version of this model, to determine whether computer macros presented systematic estimation biases. In this case, the parameter $\beta_{1}$, which denotes the (logit-transformed) average parasitism rate in the "computer estimates" model, was simply changed to be macro-specific: 
$$
P_{i,m} \sim \mathrm{Beta}(\mu_{i,m}, \phi), \\
\mathrm{logit}(\mu_{i,m}) = \beta_{1[m]} + \gamma_{i},
$$
with the other parts of the model remaining unchanged.

## S5.7 -  Validation of the experimental design (Supplementary Material S3)

As a measure of dispersal distance, we used the mean distance from release $\bar{D}_{i,m}$ between the eggs laid in a replicate $i$ (as observed by macro $m$) and the corresponding parental patch using data from the starting generation, when there were only 5 patches per replicate (including the release patch). This means $\bar{D}_{i,m}$ can only take values in the $\left]0, 4\right[$ range, and can be modelled as follows:

$$ 
\frac{\bar{D}_{i,m}}{4} \sim \mathrm{Beta}(\mu_{i,m}, \phi), \\
\mathrm{logit}(\mu_{i,m})= \beta_{\text{TREATMENT}[i]} + \alpha_{m},\\
\alpha_{m} \sim \mathrm{Normal}(0,\sigma_{\alpha}).
$$
As in other Beta models, we used a $\mathrm{Normal}(0,1.5)$ prior for the treatment-specific intercepts $\beta$, and $\mathrm{Half\mbox{-}Normal}(0,1)$ priors for both the random effect standard deviation $\sigma_{\alpha}$ and $1/\phi$.



# S6 - Supplementary figures for main text models (simulated data)

For simulations, it can be useful to show a bit more precisely how well the theory-based model(s) fit the simulated data. (For experimental data, there are already plots filling that role in the main text)

## Expansion velocity

Looking at front location as a fonction of time will not make for informative figures, since the overall linear pattern will mask any fine differences. Let's look instead at the front velocity and how it converges:

```{r load-data-s6}
## see main script 3 for details about this code chunk

data <- read_csv(file = here("NetLogo_output/model-output.csv"))

data_front <- data %>%
  filter(is.edge == TRUE) %>%
  mutate(front = pxcor) %>%
  mutate(K = factor(K)) %>% 
  mutate(treatment = fct_recode(treatment,`weak Allee effect` = "weak Allee effect (a = 0.95)"))
data_front_part <- data_front %>% filter((ticks %% 5) == 0)

data_genetics <- data %>%
  group_by(ticks, treatment, is.edge, K) %>% # we group by "type" of patch and generation
  summarise(varP1 = var(P1), varP0 = var(P0)) %>% # we can use either. They are going to be the same for a biallelic locus: var = p(1-p)
  mutate(K = factor(K)) %>% 
  ungroup() %>% 
  mutate(treatment = fct_recode(treatment,`weak Allee effect` = "weak Allee effect (a = 0.95)"))


load(here("R_output", "model5_front_IBM.Rdata"))

load(here("R_output", "model5bis_front_IBM_power.Rdata"))


load(here("R_output", "model6_genetics_IBM.Rdata"))
```


```{r figure-s6-1a, fig.width=10}

newdata <- data_front_part %>% 
  mutate(treatment = relevel(factor(treatment), ref = "reference")) %>%
  mutate(treatment = fct_relevel(treatment, "reduced connectivity", after = Inf)) %>%
  mutate(treatment = fct_relevel(treatment, "reduced + DDD", after = Inf)) %>% 
  mutate(Kbis= paste ("K = ", K))

newdata %>% 
  select(treatment, K, Kbis)  %>% 
  distinct() %>%
  expand_grid(ticks = c(1,c(1:20)*5)) %>%
  add_fitted_draws(mod_front_IBM,re_formula=NA) %>%
  ungroup() %>%
  ggplot() +
  stat_pointinterval(data = newdata, aes(x = ticks, y = front/ticks, group = ticks),
                     .width=c(0.01,0.95),col="grey",alpha=0.9) +
  stat_lineribbon(aes(x = ticks, y = .value/ticks),
                  .width = 0.95, alpha = 0.5, point_interval = mean_hdi) +
  scale_y_continuous("mean speed since start of experiment (patches per generation)") +
  scale_x_continuous("time since start (generations)")+
  facet_grid(rows=vars(Kbis), cols=vars(treatment)) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95") + 
  labs(title="with exponential model predictions superimposed") + 
  theme(legend.position = "none")
```


```{r figure-s6-1b, fig.width=10}

newdata %>% 
  select(treatment, K, Kbis)  %>% 
  distinct() %>%
  expand_grid(ticks = c(1,c(1:20)*5)) %>%
  add_fitted_draws(mod_front_IBM2,re_formula=NA) %>%
  ungroup() %>%
  ggplot() +
  stat_pointinterval(data = newdata,
                     aes(x = ticks, y = front/ticks, group = ticks),
                     .width=c(0.01,0.95),col="grey",alpha=0.9) +
  stat_lineribbon(aes(x = ticks, y = .value/ticks),
                  .width = 0.95, alpha = 0.5, point_interval = mean_hdi) +
  scale_y_continuous("mean speed since start of experiment (patches per generation)") +
  scale_x_continuous("time since start (generations)")+
  facet_grid(rows=vars(Kbis), cols=vars(treatment)) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95")+
  labs(title="with power-law model predictions superimposed") + 
  theme(legend.position = "none")
```

**Figure S6.1** Observed and predicted expansion velocities (distance to the starting patch divided by time since start) as a function of $K$, time since start and treatment. Observed simulation data are summarised by their means and 2.5/97.5% quantiles to keep the figure readable. The mean prediction curves are displayed along with their 95% credible bands. Note how predictions based on the power-law model start to systematically underestimate true speeds towards the end of the simulations, while the exponential predictions catch the fact speed has converged.

## Genetic diversity

```{r figure-6-2, fig.width = 10}
data_genetics %>% 
  mutate(treatment = relevel(factor(treatment), ref = "reference")) %>%
  mutate(treatment = fct_relevel(treatment, "reduced connectivity", after = Inf)) %>%
  mutate(treatment = fct_relevel(treatment, "reduced + DDD", after = Inf)) %>% 
  select(treatment, K, is.edge)  %>% 
  distinct() %>%
  expand_grid(ticks = c(1,c(1:20)*5)) %>%
  add_fitted_draws(mod_genetics_IBM,re_formula=NA) %>%
  ungroup() %>%
  mutate(Kbis= paste ("K = ", K),
         Location=fct_recode(factor(is.edge),core="FALSE",edge="TRUE")) %>% 
  ggplot() +
  stat_lineribbon(aes(x = ticks, y = .value, group=is.edge),
                  .width = 0.95, alpha = 0.35, fill="grey", point_interval = mean_hdi)+
  geom_line(data = data_genetics %>%  
              mutate(Kbis = paste("K = ", K), Location=fct_recode(factor(is.edge),core="FALSE",edge="TRUE")),
            aes(x = ticks, y = varP1, group=is.edge, col=Location)) +
  scale_color_manual(values=c("#998ec3", "#f1a340"))+
  scale_y_continuous("among-replicate genetic variance") +
  scale_x_continuous("time since start (generations)")+
  facet_grid(rows=vars(Kbis), cols=vars(treatment)) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95")
```

**Figure S6.2** Observed (colored lines) and predicted (grey bands) among-replicate genetic variances in simulations as a function of $K$, time since start and treatment. The mean prediction curves are displayed along with their 95% credible bands.

# S7 - Summary tables for main text models

We here present posterior means and 95% credible intervals for some parameters of interest of the models discussed in the main text. For conciseness, we: 

- focus on fixed effect parameters as they are the ones that interest us in the present study;

- only present the information from the model actually discussed in the main text when there are two competing models (i.e. exponential vs. power for velocities).

The interested reader can get the same information for all other parameters by running the corresponding `Rmd` scripts (scripts 1 and 3 in archived code), which contain various summary calls. Parameter names in the tables below are as in **Supplementary Material S5**.

## Expansion velocity

**Table S7.1** Posterior means [95% credible intervals] for the model fitted to analyse expansion speeds of *simulated* range expansions

```{r table7-1}
load(here("R_output", "model5_front_IBM.Rdata"))

mod_front_IBM %>%
  posterior_samples() %>%
  select(starts_with("b_")) %>% #we keep only fixed effects coefs
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(entry = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>% #rounding everything for consistency
  mutate(treatment = ifelse(str_detect(name, "reference"), "reference", name)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "density"), "density-dependent dispersal", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "connectivity"), "reduced connectivity", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "Allee"), "weak Allee effect", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "DDD"), "reduced connectivity + DDD", treatment)) %>%
  mutate(K = ifelse(str_detect(name, "225"), 225, 450)) %>%
  mutate(parameter = str_split_fixed(name, "_", 3)[, 2]) %>%
  select(parameter, K, treatment, entry) %>%
  pivot_wider(names_from = treatment, values_from = entry) %>%
  arrange(parameter == "logitspeedasym") %>%
  mutate(name = c(rep("$\\log_{10}(\\lambda)$", 2), rep("$\\mathrm{logit}(v_{t \\to \\infty})$", 2))) %>%
  mutate(name = paste(name, ", $K$", "=", K, sep = "")) %>%
  select(name, reference, `density-dependent dispersal`, `weak Allee effect`, `reduced connectivity`, `reduced connectivity + DDD`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```

**Table S7.2** Posterior means [95% credible intervals] for the model fitted to analyse expansion speeds of *experimental* range expansions

```{r table7-2}

load(here("R_output", "model1_front_expe.Rdata"))

mod_front %>%
  posterior_samples() %>%
  select(starts_with("b_")) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(entry = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(treatment = ifelse(str_detect(name, "reference"), "reference", "reduced connectivity")) %>%
  mutate(parameter = str_split_fixed(name, "_", 3)[, 2]) %>%
  select(parameter, treatment, entry) %>%
  pivot_wider(names_from = treatment, values_from = entry) %>%
  mutate(name = c("$\\log_{10}(\\lambda)$", "$\\log(v_{t \\to \\infty})$", "$\\log(v_{t = 1})$")) %>%
  select(name, reference, `reduced connectivity`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```

## Genetic diversity


```{r table7-genetdata}
load(here("R_output", "model6_genetics_IBM.Rdata"))
```

**Table S7.3** Posterior means [95% credible intervals] for the model fitted to analyse genetic diversity of *simulated* range expansions

```{r table7-3}
mod_genetics_IBM %>%
  posterior_samples() %>%
  select(starts_with(c("b_logdecay"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(entry = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(treatment = ifelse(str_detect(name, "reference"), "reference", name)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "density"), "density-dependent dispersal", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "connectivity"), "reduced connectivity", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "Allee"), "weak Allee effect", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "DDD"), "reduced connectivity + DDD", treatment)) %>%
  mutate(K = ifelse(str_detect(name, "225"), 225, 450)) %>%
  mutate(location = ifelse(str_detect(name, "is.edgeFALSE"), "core", "edge")) %>%
  mutate(parameter = str_split_fixed(name, "_", 3)[, 2]) %>%
  select(parameter, K, treatment, location, entry) %>%
  pivot_wider(names_from = treatment, values_from = entry) %>%
  mutate(name = c(rep("$\\log_{10}(\\lambda)$", 4))) %>%
  mutate(name = paste(name, ", $K$", "=", K, ", ", location, " patches", sep = "")) %>%
  select(name, reference, `density-dependent dispersal`, `weak Allee effect`, `reduced connectivity`, `reduced connectivity + DDD`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```

```{r table7-3b}
mod_genetics_IBM %>%
  posterior_samples() %>%
  select(starts_with(c("b_logitVmax"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(`all treatments` = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(name = "$\\mathrm{logit}(V_{max})$") %>%
  select(name, `all treatments`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```


**Table S7.4** Posterior means [95% credible intervals] for the model fitted to analyse genetic diversity of *experimental* range expansions

```{r table7-4data}
load(here("R_output", "model2_genet_expe.Rdata"))
```


```{r table7-4}
mod_genetics %>%
  posterior_samples() %>%
  select(starts_with(c("b_logdecay"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(entry = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(treatment = ifelse(str_detect(name, "reference"), "reference", "reduced connectivity")) %>%
  mutate(parameter = ifelse(!str_detect(name, "is.edge"), "average $\\log_{10}$(decay rate of genetic diversity) ($\\beta_{1}$)", "difference edge-core in decay rate ($\\beta_{2}$)")) %>%
  select(parameter, treatment, entry) %>%
  pivot_wider(names_from = treatment, values_from = entry) %>%
  column_to_rownames(var = "parameter") %>%
  kable(format = "html") %>%
  kable_styling()
```

```{r table7-4b}
mod_genetics %>%
  posterior_samples() %>%
  select(starts_with(c("b_logitH0"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(`all treatments` = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(name = "logit of initial genetic diversity ($\\beta_{0}$)") %>%
  select(name, `all treatments`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```

## Population size (experimental data)

**Table 7.5** Posterior means [95% credible intervals] for the *univariate* model fitted to analyse mean population size in core patches (x = 0) during *experimental* range expansions

```{r table 7-5}
load(here("R_output", "model3bis_popsize_expe.Rdata"))

mod_popsize2 %>% 
  posterior_samples() %>%  ##get coefficient posteriors 
  select(contains("b_")) %>%             ##keep only fixed effects
  mutate(.iteration = 1:dim(.)[1]) %>% 
  pivot_longer(cols=-.iteration) %>% 
  group_by(name) %>% 
  mean_hdi() %>% 
  mutate(entry = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(treatment = ifelse(str_detect(name, "reference"), "reference", "reduced connectivity")) %>%
  mutate(name = "logit of carrying capacity ($K$)") %>%
  select(name, entry, treatment) %>% 
  pivot_wider(names_from = treatment, values_from = entry) %>%
  select(name, reference, `reduced connectivity`) %>% 
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()

```


# References
