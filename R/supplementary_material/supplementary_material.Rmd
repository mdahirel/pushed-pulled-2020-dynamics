---
title: "Supplementary Material for \"Shifts from pulled to pushed range expansions caused by reduction of landscape connectivity\" " 
author: "Maxime Dahirel, Aline Bertin, Marjorie Haond, Aurélie Blin, Eric Lombaert, Vincent Calcagno, Simon Fellous, Ludovic Mailleret, Thibaut Malausa, Elodie Vercken (code by M. Dahirel)"
date:
output: 
  html_document:
    theme: yeti
    toc: TRUE
    toc_float: TRUE
editor_options:
  chunk_output_type: console
bibliography: references.bib
csl: journal-of-animal-ecology.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
```

```{r packages-loading}
library(arm)

library(adegenet)

library(modelr)
library(RColorBrewer)

### inference
library(coda)
library(rstan)
library(brms)
rstan_options(auto_write = TRUE)
options(mc.cores = 2)


library(tidyverse)

library(tidybayes)
library(bayesplot)

library(patchwork)

library(knitr)
library(kableExtra)

library(cowplot)

library(here)
```

```{r color-palettes}

TRTpalette <- c("#d8b365", "#5ab4ac")
edgecorePalette <- c("#f1a340", "#998ec3")
```

<br/>
<br/> 
**Note: ** The full code for the following document and the analyses it describes, as well as for all analyses described in the main text, is available on GitHub [here](https://github.com/mdahirel/pushed-pulled-2020-dynamics) and Zenodo: [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3969988.svg)](https://doi.org/10.5281/zenodo.3969988).

# S1 - Creation of genetic lines

*Trichogramma brassicae* wasps used in the experiment were derived from hybrid populations created in 2013 by mixing parental strains sampled in 24 sites in Western Europe.  These parental strains were initially collected for a project on artificial selection and phenotype amelioration of *T. brassicae* strains for biological control. Isoline populations were then maintained under standard conditions between 2014 and 2016 (18 ± 0.5 °C, 65 ± 10% relative humidity, L:D 18:6), for approximately 20 generations. 

To generate independent experimental replicates with comparable levels of initial genetic diversity, and to allow for evolutionary dynamics, we created three genetic mixes from three isoline populations each (using nine distinct isoline populations in total). We followed the protocol from Fellous *et al.*  [-@fellousCombiningExperimentalEvolution2014] to create mixes with homogeneous genetic background (i.e. similar representation of each of the three ancestral isolines). First, we performed all possible two-by-two crosses between the three isolines. The F1 progeny of each two-by-two cross was then crossed with the third remaining isoline. The F2 individuals from these crosses were then inbred for 2 generations to favour recombination. Individuals from these F4 were then mixed all together in equal proportions to form each final genetic mix. While they did differ from each other, all three mixes had broadly similar levels of genetic diversity at the start of the experiments (**Supplementary Figure S1.1**).

```{r supplementary-figure-1}
raw_genetics <- read_csv(here("data/Trichogramma_genetics.csv"),
  col_types = cols(.default = col_character())
)

## more or less a re-thread of the script used to create the "empirical genetics" dataset in the main code, see there for more details

data_genetics <- raw_genetics %>%
  mutate( ### info on variables is contained in each sample ID
    Generation = str_extract(ID, "G0|G4|G8|G12"),
    Mix = str_extract(ID, "_1P|_2P|_3P"),
    Treatment = str_extract(ID, "PL|PS"),
    Replicate = str_extract(ID, "L_[:digit:]|S_[:digit:]")
  ) %>%
  mutate(
    Generation = as.numeric(str_extract(Generation, "0|4|8|12")),
    Mix = as.numeric(str_extract(Mix, "1|2|3")),
    Replicate = as.numeric(str_extract(Replicate, "[:digit:]"))
  ) %>%
  filter(Generation == 0) %>%  ## we only want diversity at t=0 for this supplementary figure
  mutate(Location = "origin") %>%
  mutate(landscapeID = paste("Mix", Mix, "_Treatment", Treatment, "_Replicate", Replicate, sep = ""))

### STEP 2 isolate the genetics markers
genmat <- df2genind(select(data_genetics, starts_with("TB")), #### all allelic columns start with a "P"
  ncode = 3,
  NA.char = "000",
  ind.names = data_genetics$ID, pop = data_genetics$landscapeID
) # ncode=3 bc 3 characters for one allele

### STEP 3 generate summary of all other columns ; one row = one sampled patch
data_genetics <- data_genetics %>%
  group_by(landscapeID) %>%
  mutate(Nsampled = length(Location)) %>%
  ungroup() %>%
  select(-starts_with("TB"), -ID) %>%
  distinct() %>%
  inner_join(
    tibble(Hexp = Hs(genmat), landscapeID = names(Hs(genmat)))
  )

data_genetics %>%
  ggplot() +
  geom_boxplot(aes(x = factor(Mix), y = Hexp), alpha = 0.2) +
  geom_jitter(aes(x = Mix, y = Hexp), pch = 20, size = 4) +
  scale_y_continuous(name = "Genetic diversity at the start of the experiment (exp. heterozygosity)", limits = c(0.1, 0.45)) +
  scale_x_discrete("Genetic Mix") +
  theme_bw()
```

**Supplementary Figure S1.1** Genetic diversity (multilocus expected heterozygosity) as a function of genetic mix at the start of the experiment. One dot = one experimental landscape. The y axis is scaled to show the full range of genetic diversities observed during the course of the experiment, for reference (see main text)

# S2 - Validating computer estimates of *Trichogramma* population sizes

For analyses asking for population sizes (Supplementary Material 3 and 9), the proportion of parasitized eggs was estimated based on egg strip photographs using ImageJ [@abramoffImageProcessingImageJ2004] and the `CODICOUNT` plugin [@perezMethodeAnalyseImage2017].  `CODICOUNT` estimates the number of pixels assigned to parasitized host eggs, unparasitized host eggs and background after training. We tested each photograph using 4 macros, each trained on a different set of pictures (from generations 1 2, 3 and 13 respectively) and each potentially having its own systematic bias, combined to better approximate real rates. Proportions of pixels identified as “egg” that were also identified as “parasitized” were used as our estimate of parasitism rate/ population size.

To assess the validity of these automated counts, we manually counted parasitized egg plates from 197 patches (out of 2725 photographed for the experiment) roughly spanning the full range of possible population sizes (human count range: 17 to 443; number of hosts per population ≈ 450). 

```{r data-validate}

raw_dynamics <- read_csv(here("data", "Trichogramma_dynamics.csv"))

data_validate <- raw_dynamics %>%
  mutate(
    Mix = as.numeric(str_sub(Image, 1, 1)),
    Dynamics = str_sub(Image, 2, 3),
    Replicate = as.numeric(str_sub(Image, 4, 4)),
    Patch = as.numeric(str_sub(Image, 6, 7))
  ) %>%
  # no further processing needed; we exploit the fact that chars 6&7 are either digit dot (patchs 0 to 9)
  # or digit-digit (patches 10 and beyond)
  ## as.numeric() resolves both correctly (e.g; "2." and "12" become 2 and 12)
  mutate(landscapeID = paste("Mix", Mix, "_Dynamics", Dynamics, "_Replicate", Replicate, sep = "")) %>%
  mutate(
    Peggs_est = P / (P + H), ## proportion of pixels counted as parasitised (estimated)
    spacetimeID = paste(landscapeID, "_Generation", Generation, "_Patch", Patch, sep = ""), # a unique ID for each replicate x patch x generation combination
    Mix = factor(Mix)
  ) %>%
  group_by(spacetimeID) %>%
  filter(sum(is.na(obs_count) == FALSE) > 0) %>% ### we group by spacetimeID (replicate, patch, time) and we filter out all cases without a human count to validate against
  mutate(Neggs_obs = replace_na(obs_count, 0)) ### there are 4 macro counts but only one human count per spacetimeID (put on the same row as one of the macro counts); the other three are NAs, need to contain filler values (0 here) for the bivariate model to work, which won't be used in the analyses)
```

```{r model-validate}
if (file.exists(here("R_output", "supplementary", "model_S2_computercounts.Rdata"))) {
  load(here("R_output", "supplementary", "model_S2_computercounts.Rdata"))
} else {
  prior_validate <- c(
    set_prior("normal(0,1.5)", class = "Intercept", resp = "Neggsobs"),
    set_prior("normal(0,1)", class = "sd", resp = "Neggsobs"),

    set_prior("normal(0,1.5)", class = "Intercept", resp = "Peggsest"),
    set_prior("normal(0,1)", class = "sd", resp = "Peggsest"), ## half-normal is implied for sd pars in brms
    set_prior("normal(0,1)", nlpar = "invphi", resp = "Peggsest", lb = 0), ## but has to be made explicit for many other types of pars with lb
    set_prior("lkj(2)", class = "cor")
  )

  bf_validate_obs <- bf(Neggs_obs | trials(450) + subset(Neggs_obs > 0) ~ (1 | 1 | spacetimeID), family = binomial)
  bf_validate_estimated <- bf(Peggs_est ~ (1 | 1 | spacetimeID),
    nlf(phi ~ 1 / invphi),
    invphi ~ 1,
    family = Beta(link_phi = "identity")
  )

  mod_validate <- brm(
    mvbf(bf_validate_obs + bf_validate_estimated),
    data = data_validate,
    chains = 4, iter = 22000, warmup = 2000, prior = prior_validate, seed = 42
  )


  save(list = "mod_validate", file = here("R_output", "supplementary", "model_S2_computercounts.Rdata"))
}
```


```{r model-validate-postprocess1}
# latent-scale correlation between human observed and consensus computer values
cor_latent <- posterior_samples(mod_validate) %>%
  select(.value = contains("cor")) %>%
  mean_hdi()

newdata <- filter(data_validate, Macro == "MacroG3") %>% ## selecting a Macro at random, it's just for generating predictions and plots
  ungroup() %>%
  mutate(Neggs_obs = 2, prop_para_pix = 0.2, #again arbitrary and won't be used, we just need the columns to exist for prediction function to work well
         Nhosts = 450) %>%
  select(Nhosts, Peggs_est, Neggs_obs, spacetimeID, Macro) %>%
  distinct()
```


```{r model-validate-postprocess2}

preds_obs <- newdata %>%
  add_fitted_draws(mod_validate, resp = "Neggsobs", value = "human", re_formula = ~ (1 | spacetimeID)) %>%
  ungroup()

## we want "consensus"/"average" computer predictions, so we don't include the Macro effect in the re_formula
preds <- newdata %>%
  add_fitted_draws(mod_validate, resp = "Peggsest", value = "estimated", re_formula = ~ (1 | spacetimeID)) %>%
  ungroup() %>%
  mutate(human = preds_obs$human / 450)
```

```{r model-validate-postprocess3}
##now we have the observed scale predictions, we can estimate the correlation between human and computer on that scale too
## we group by iteration and estimate the correlation for each
cor_obs <- preds %>%
  group_by(.draw) %>%
  nest() %>%
  mutate(.value = map(data, ~ cor.test(.$estimated, .$human)$est)) %>%
  unnest(.value) %>%
  select(.draw, .value) %>%
  ungroup() %>%
  mean_hdi()

##we also need to look at a potential bias: do computer estimates systematically under or over estimate?

diff_obs_est <- preds %>%
  mutate(diff = human - estimated) %>%
  group_by(.draw) %>%
  summarise(diff = 100 * mean(diff)) %>%
  mean_hdi()
```

We then used a bivariate generalized linear mixed model approach to compare computer estimates and human counts, with a Beta family used for the former and a binomial distribution for the latter. Both models contained a fixed-effect intercept as well as random intercepts of population/patch identity, which were correlated. This approach accounts for the data structure and the fact both human- and computer-derived counts are likely estimated with error [@perezMethodeAnalyseImage2017]. It allows us to estimate the correlation between human counts and “consensus” computer counts obtained from pooling information from all macros. 

Estimated and human-observed parasitism rates were highly correlated both on the latent logit scale (*r*= `r round(cor_latent$.value,2)` [`r round(cor_latent$.lower,2)`, `r round(cor_latent$.upper,2)`]) and on the observed scale (*r* = `r round(cor_obs$.value,2)` [`r round(cor_obs$.lower,2)`, `r round(cor_obs$.upper,2)`]). There was also no evidence of bias (predicted difference between average "human" and "computer" parasitism rates, in % of hosts per patch = `r round(diff_obs_est$diff,2)`% [`r round(diff_obs_est$.lower,2)`, `r round(diff_obs_est$.upper,2)`])

We then refitted this model, this time adding a fixed effect of the macro in the "computer estimates" submodel, to determine whether macros presented systematic biases. We found that the overall absence of bias of the "consensus" estimates (see above) actually resulted from the majority of macros slightly underpredicting human-observed parasitism rates while one consistently overpredicted them (**Supplementary Figure S2.1**).

```{r model-validate2}
if (file.exists(here("R_output", "supplementary", "model_S2_computercountsbymacro.Rdata"))) {
  load(here("R_output", "supplementary", "model_S2_computercountsbymacro.Rdata"))
} else {
  prior_validate <- c(
    set_prior("normal(0,1.5)", class = "Intercept", resp = "Neggsobs"),
    set_prior("normal(0,1)", class = "sd", resp = "Neggsobs"),

    set_prior("normal(0,1.5)", class = "b", resp = "Peggsest"),
    set_prior("normal(0,1)", class = "sd", resp = "Peggsest"), ## half-normal is implied for sd pars in brms
    set_prior("normal(0,1)", nlpar = "invphi", resp = "Peggsest", lb = 0), ## but has to be made explicit for many other types of pars
    set_prior("lkj(2)", class = "cor")
  )

  bf_validate_obs <- bf(Neggs_obs | trials(450) + subset(Neggs_obs > 0) ~ (1 | 1 | spacetimeID), family = binomial)
  bf_validate_estimated <- bf(Peggs_est ~ 0 + Macro + (1 | 1 | spacetimeID),
    nlf(phi ~ 1 / invphi),
    invphi ~ 1,
    family = Beta(link_phi = "identity")
  )

  mod_validate2 <- brm(
    mvbf(bf_validate_obs + bf_validate_estimated),
    data = data_validate,
    chains = 4, iter = 22000, warmup = 2000, prior = prior_validate, seed = 42
  )

  save(list = "mod_validate2", file = here("R_output", "supplementary", "model_S2_computercountsbymacro.Rdata"))
}

obs <- data_validate %>%
  ungroup() %>%
  mutate(spacetimeID = spacetimeID[1], Neggs_obs = 1) %>%
  select(spacetimeID, Macro, Neggs_obs) %>%
  distinct() %>%
  add_fitted_draws(mod_validate2, resp = "Neggsobs", re_formula = NA) %>%
  mean_hdi()

data_validate %>%
  ungroup() %>%
  mutate(spacetimeID = spacetimeID[1], Neggs_obs = 1) %>%
  select(spacetimeID, Macro, Neggs_obs) %>%
  distinct() %>%
  add_fitted_draws(mod_validate2, resp = "Peggsest", re_formula = NA) %>%
  ggplot() +
  geom_hline(aes(yintercept = obs$.value[1] / 450), size = 1.2) +
  geom_hline(aes(yintercept = obs$.lower[1] / 450), lty = 2) +
  geom_hline(aes(yintercept = obs$.upper[1] / 450), lty = 2) +
  stat_eye(aes(Macro, .value)) +
  scale_y_continuous("Parasitism rate", limits = c(0.25, 0.75)) +
  theme_bw()
```

**Supplementary Figure S2.1** Posterior mean estimated parasitism rate, by computer macro, for the 197 plates used to compare human and computer counts. Horizontal lines denote the mean (bold line) and 95% credible interval (dotted lines) for the posterior mean parasitism rate based on human counts.

# S3 – Validation of the experimental design

To determine whether our experimental reduction of connectedness did limit individual movement (i.e. functional connectivity), we used data from the first generation of testing, i.e. the only time the patch of origin of all parents can be known with certainty. 

We used parasitism rates to calculate for each landscape × macro the average egg location (in patches from release) and used it as a proxy of dispersal. We analysed this distance using a Beta generalised linear mixed model (dividing it by 4, the maximal possible distance, to ensure it stayed between 0 and 1). The model included a fixed effect of treatment, as well as a random effect of macro (random intercept) to account for uncertainty in our estimates of parasitism and distances, more specifically for macro-level systematic biases.

We found that released wasps did lay their eggs closer from release sites in landscapes with reduced connectedness compared to reference landscapes (**Supplementary Figure S3.1**).

```{r data-G0}
raw_dynamics <- read_csv(here("data", "Trichogramma_dynamics.csv"))

data_popsize_temp <- raw_dynamics %>%
  mutate(
    Mix = as.numeric(str_sub(Image, 1, 1)),
    Treatment = str_sub(Image, 2, 3),
    Replicate = as.numeric(str_sub(Image, 4, 4)),
    Patch = as.numeric(str_sub(Image, 6, 7))
  ) %>%
  # no further processing needed; we exploit the fact that chars 6&7 are either digit dot (patchs 0 to 9)
  # or digit-digit (patches 10 and beyond)
  ## as.numeric() resolves both correctly (e.g; "2." and "12" become 2 and 12)
  mutate(landscapeID = paste("Mix", Mix, "_Treatment", Treatment, "_Replicate", Replicate, sep = "")) %>% # a unique replicate ID
  mutate(
    Peggs_est = P / (P + H), ## proportion of pixels counted as parasitised (estimated)
    spacetimeID = paste(landscapeID, "_Generation", Generation, "_Patch", Patch, sep = ""), # a unique ID for each replicate x patch x generation combination
    Mix = factor(Mix)
  ) %>%
  mutate(Treatment = fct_recode(Treatment, `reference` = "PL", `reduced connectedness` = "PS"))

data_G0 <- filter(data_popsize_temp, Generation == 1 & Patch <= 4) %>%
  ## only patches 0 to 4 are available at start (adding "Patch <=4" above is not necessary, but it makes it explicit)
  select(landscapeID, Mix, Treatment, Patch, Peggs_est, Macro) %>%
  ungroup() %>%
  pivot_wider(., names_from = "Patch", values_from = c("Peggs_est"), names_prefix = "P") %>%
  filter(is.na(P0) == FALSE) %>% ## remove one row with the one macro with missing info for "resident" eggs (can't estimate dispersal)
  mutate(P1 = replace_na(P1, 0)) %>%
  mutate(P2 = replace_na(P2, 0)) %>%
  mutate(P3 = replace_na(P3, 0)) %>%
  mutate(P4 = replace_na(P4, 0)) %>%
  mutate(Pall = (P0 + P1 + P2 + P3 + P4)) %>%
  mutate(
    distmean = (1 * P1 + 2 * P2 + 3 * P3 + 4 * P4) / Pall) %>% ## mean distance from release
  mutate(jitteredTRT = jitter(as.numeric(factor(Treatment)))) %>% ## just for pretty plotting
  group_by(landscapeID) %>%
  mutate(jitteredTRT = mean(jitteredTRT)) %>% ## same: ensures same jitter for same measure from different macros
  ungroup()
```


```{r model-g0}

if (file.exists(here("R_output", "supplementary", "model_S3_initialdispersal.Rdata"))) {
  load(here("R_output", "supplementary", "model_S3_initialdispersal.Rdata"))
} else {
  mod_G0 <- brm(bf(
    distmean / 4 ~ 0 + Treatment + (1 | Macro),
    ### divided by 4 because it's the maximal possible distance possible at G0
    nlf(phi ~ 1 / invphi),
    invphi ~ 1
  ),
  data = data_G0, family = Beta(link_phi = "identity"),
  iter = 6000, chains = 4,
  prior = c(
    set_prior("normal(0,1.5)", class = "b"),
    set_prior("normal(0,1)", class = "sd"),
    set_prior("normal(0,1)", nlpar = "invphi", lb = 0)
  ),
  control = list(adapt_delta = 0.995), seed = 42
  )

  save(list = "mod_G0", file = here("R_output", "supplementary", "model_S3_initialdispersal.Rdata"))
}
```

```{r figure-G0}

newdata <- data_G0 %>%
  mutate(Macro = Macro[1]) %>% # it's just a placeholder, we plot the posterior for the "true" (grand) mean distance, without random effects
  select(Macro, Treatment) %>%
  distinct()

## these averages are just indicative and for plotting purposes
data_G0_avg <- data_G0 %>%
  group_by(landscapeID, Treatment) %>%
  summarise(
    distmean = mean(distmean),
    jitteredTRT = mean(jitteredTRT)
  ) %>%
  ungroup()

## the main plot
p1 <- newdata %>%
  add_fitted_draws(mod_G0, re_formula = NA) %>%
  ggplot() +
  stat_eye(aes(x = Treatment, y = .value * 4, fill = Treatment), .width = c(0.66, 0.95), slab_alpha = 0.9, point_interval = mean_hdi) +
  ## we put both observed points (by macros) and the indicative averages for each each landscape
  geom_point(data = data_G0, aes(x = jitteredTRT, y = distmean, col = Treatment), fill = "white", pch = 21, alpha = 0.8) +
  geom_point(data = data_G0_avg, aes(x = jitteredTRT, y = distmean, fill = Treatment), pch = 21, size = 2) +
  scale_fill_manual(values = TRTpalette) +
  scale_colour_manual(values = TRTpalette) +
  scale_x_discrete("") +
  scale_y_continuous("Mean egg-laying distance from release site (patches)", limits = c(-0.2, 2.5)) +
  theme_bw()

## a subplot showing the difference between treatments
p2 <- newdata %>%
  add_fitted_draws(mod_G0, re_formula = NA) %>%
  ungroup() %>%
  compare_levels(variable = .value, by = Treatment) %>%
  ggplot() +
  stat_eye(aes(x = Treatment, y = .value * 4), .width = c(0.66, 0.95), fill = "grey", point_interval = mean_hdi) +
  scale_x_discrete("", labels = "") +
  scale_y_continuous("Difference between treatments",
    limits = c(-0.2, 2.5) - 4 * invlogit(fixef(mod_G0)["Treatmentreference", "Estimate"])
  ) + ## so the "difference" subplot is aligned with the main
  geom_hline(yintercept = 0, lty = 2) +
  theme_bw()

p1 + p2 + plot_layout(guides = "collect", widths = c(4, 1)) & theme_bw() &
  theme(legend.position = "none")


## aside plot (not shown): very roughly showing that there is indeed consistent macro-level bias even on distances
## data_G0 %>% group_by(landscapeID) %>% mutate(DD=mean(distmean)) %>% ggplot()+ geom_boxplot(aes(x=Macro,y=distmean/DD))
## likely reason: because macros that over/underestimate parasitism rates will over/underestimate # of eggs in the 4 "dispersal patches" compared to the one "resident patch", so over/underestimate distances
```

**Supplementary Figure S3.1.** Left: Mean egg-laying distance from release patch as a function of treatment. Colored areas: posterior distribution (assuming total fecundity fixed to its average); black dots and segments: posterior mean and 66/95% credible intervals; empty colored dots: estimated values for each macro; full colored dots: averages across macros for each replicate. Right: posterior difference between the two experimental treatments.

# S4 - Microsatellite genotyping, detailed methods

## S4.1 - Design of the microsatellite markers and multiplex PCR assay

Microsatellite DNA libraries were produced following the method described in Malausa *et al.* [-@malausaHighthroughputMicrosatelliteIsolation2011]. This method consists of (i) the isolation of DNA fragments containing microsatellite motifs by multiplex microsatellite enrichment (obtained via hybridisation to biotin-labelled oligonucleotides with the motifs (AG)~10~, (AC)~10~, (AAC)~8~, (AGG)~8~, (ACG)~8~, (AAG)~8~, (ACAT)~6~ and (ATCT)~6~) and (ii) the pyrosequencing of the fragments (454 GS-FLX Titanium). This protocol was applied to a sample containing DNA extracted from about 100 *Trichogramma brassicae* individuals.

The obtained DNA dataset was analyzed and primers for microsatellite amplification were designed using the QDD program [@megleczQDDUserfriendlyProgram2010], version 2.1. The default QDD parameters were used, except for: (i) the minimum percentage similarity of sequences used for the construction of consensus sequences was 90%, (ii) the proportion of sequences that must have the same base on the aligned site to accept it as a consensus was 0.66, (iii) the minimum length of PCR product for primer design was 80bp, (iv) the maximum length of PCR product for primer design was 500, (v) the maximum length of a primer was 32, (vi) the maximum acceptable difference between the melting temperatures of primers was 4°C.

Nineteen microsatellite markers were developed by testing and multiplexing part of the PCR primers selected after the QDD analysis. The main criteria for microsatellites sequences selection and primers design used were (i) the motif of the microsatellite they target, to obtain a balanced frequency of motifs, (ii) microsatellites with at least eight repeats, (iii) the size of the expected PCR products (we selected primers amplifying markers homogeneously distributed in terms of size within the range 80 bp - 500 bp).

## S4.2 - Genotyping and microsatellites description  

All *T. brassicae* wasps were stored in 70% ethanol before DNA extraction. DNA was extracted from each individual wasp, either with the prepGem Insect DNA Extraction kit from Zygem (extraction volume of 15µL per individual, using 0.375µL of prepGem enzyme; samples were placed in a thermocycler for 2 hours at 75°C and 5 minutes at 95°C), or with the Quick Extract DNA Extraction Solution from Lucigen (extraction volume of 15µL per individual; samples were placed in a thermocycler for 10 minutes at 65°C and 2 minutes at 98°C). All DNA extracts were stored at -20°C.  

For microsatellite amplification, 2µl of genomic DNA were used within a 10µL final PCR reaction consisting of 5µL of the QIAGEN PCR multiplex solution, 1µL of the primer mix of the 19 primers reverse and forward (1µM each), and water. PCR conditions were as followed: initial denaturation at 95°C for 15 min; 30 cycles of denaturation (94°C, 30s), annealing (60°C, 90s) and elongation (72°C, 60s); final extension at 60°C for 30 min.
For each individual, 1.5µL of the PCR product was mixed with 9.8µL of a mix obtained from 1mL HiDi formamide and 20µL of 500 LIZ Size Standard (Applied Biosystems). Products were then electrophoresed using an ABI PRISM 3130XL sequencer (Applied Biosystems). Finally, genotypes were scored using Gene Marker version 1.75 (SoftGenetics).

All loci are polymorphic when looking at the entire dataset (Supplementary Table S4.1). Information on each marker, including allelic richness over the whole set of genotyped individuals, is presented Supplementary Table S4.1. Information about genetic diversity and whether alleles frequencies followed the Hardy-Weinberg equilibrium **at the start of the experiment** is presented Supplementary Table S4.2.


**Supplementary Table S4.1**: Primer pairs used for the PCR set of the multiplex panel. For each of the 19 loci, the table includes: the repeat motifs in the sequence used to design primers, sequence and fluorescent dye label used for each primer, the observed number of alleles and the allelic size range. 

```{r table-microsat1}
raw_genetics <- read_csv(here("data/Trichogramma_genetics.csv"),
  col_types = cols(.default = col_character())
)

data_genetics <- raw_genetics %>%
  mutate( ### info on variables is contained in each sample ID
    Generation = str_extract(ID, "G0|G4|G8|G12"),
    Mix = str_extract(ID, "_1P|_2P|_3P")
  ) %>%
  mutate(
    Generation = as.numeric(str_extract(Generation, "0|4|8|12")),
    Mix = as.numeric(str_extract(Mix, "1|2|3"))
  )

genmat <- df2genind(select(data_genetics, starts_with("TB")), #### all allelic columns start with a "P"
  ncode = 3,
  NA.char = "000", ## missing alleles
  ind.names = data_genetics$ID, pop = data_genetics$Mix
) # ncode=3 bc 3 characters for one allele


test <- enframe(genmat@all.names) %>%
  unnest(cols = value) %>%
  mutate(value = as.numeric(value)) %>%
  filter(value > 0) %>% ## remove missing alleles (scored as 0s)
  group_by(name) %>%
  summarise(min = min(value), max = max(value)) %>%
  mutate(range = paste(min, "-", max)) %>%
  left_join(tibble(nAll = nAll(genmat), name = names(nAll(genmat)))) %>%
  select(Locus = name, `number of alleles` = nAll, `Size range (bp)` = range)

read_csv(here("data", "Trichogramma_microsatellite_description.csv")) %>%
  rename(Locus = "locus", `Repeat motif` = "motif", Forward = "forward_primer", Reverse = "reverse_primer", `Fluorescent dye` = "dye") %>%
  left_join(test) %>%
  kable(format = "html") %>%
  kable_styling() %>%
  add_header_above(c(" " = 2, "Primer sequences (5'—3')" = 2, " " = 3)) %>%
  collapse_rows(5, valign = "top") ##
```

**Supplementary Table S4.2**: Population genetics statistics **at the start of the experiment** (Generation 0 samples). At each locus described Supplementary Table S4.1, the number of individuals successfully genotyped (*N*, excluding missing alleles),the observed heterozygosity (*H~O~*), the expected heterozygosity (*H~E~*, @neiAnalysisGeneDiversity1973) and the *p*-value for the exact test of Hardy–Weinberg equilibrium were computed separately for each of the 3 genetic mixes used (Mix1, Mix2, Mix3; See Supplementary Material S1). Statistics were computed using the `adegenet` [@jombartAdegenetPackageMultivariate2008] and `pegas` [@paradisPegasPackagePopulation2010] R packages. Note that all loci were found to be polymorphic when analysing the whole set of wasps used in the experiment (See Supplementary Table S4.1).

```{r table-microsat2}

data_genetics <- data_genetics %>%
  filter(Generation == 0)

genmat <- df2genind(select(data_genetics, starts_with("TB")), #### all allelic columns start with a "P"
  ncode = 3,
  NA.char = "000", ## missing alleles
  ind.names = data_genetics$ID, pop = data_genetics$Mix
) # ncode=3 bc 3 characters for one allele

seppop(genmat) %>% #we split by Mix, and for each mix we obtain some popgen metrics
  map(
    .x = .,
    .f = ~ tibble(
      Locus = locNames(.x),
      N = seploc(.x) %>% ### a very convoluted way to get N because nInd(.x) doesn't account for NAs
        map(
          .x = ., ### so for each locus
          .f = ~ tab(.x) %>% ### we get the table of allelic frequencies
            rowSums() %>% ### we sum by individuals
            na.omit() %>% ### we remove the NAs
            length() ### we count
        ) %>%
        unlist(),
      Ho = summary(.x)$Hobs %>% round(2),
      He = summary(.x)$Hexp %>% round(2),
      HW = pegas::hw.test(.x)[, "Pr.exact"] %>% round(2)
    )
  ) %>%
  enframe() %>%
  unnest(cols = c(value)) %>%
  rename(Mix = "name") %>%
  mutate(HW = as.character(HW)) %>%
  mutate(HW = ifelse(Ho == 0 & He == 0, "--", HW)) %>%  #if no diversity *in sample*, no valid Hardy-Weinberg equilibrium test
  group_by(Locus) %>%
  summarise(`*N*` = paste(N, collapse = ", "), `*H~O~*` = paste(Ho, collapse = ", "), `*H~E~*` = paste(He, collapse = ", "), `HWE *p*-value` = paste(HW, collapse = ", ")) %>%
  kable(format = "simple")
```


# S5 - Detailed description of models (main text)

We here describe the full structure of the models presented in the main text, as well as associated prior choices. We try to follow throughout the same notation conventions as McElreath [-@mcelreathStatisticalRethinkingBayesian2020]. Variable names and indices are reset from one model to the next, for simplicity, but similar names always refer to similar types of variables (fixed effects/random effects/correlations...). All Beta models described in here and in S10 use the (mean, precision) parametrisation of the Beta distribution.

## S5.1 - Genetic diversity, experimental data

We can describe the genetic diversity (expected heterozygosity) $H_{x,i,t}$ of a patch in replicate $i$, with $x$ denoting the location of that patch (0 for core patches, 1 for front patches) and $t$ the number of generations since release, the following way:

$$ 
\mathrm{logit}(H_{x,i,t}) \sim \mathrm{StudentT}(\mathrm{logit}(\mu_{x,i,t}) , \sigma_{d} , \nu )
$$
where $\mu_{x,i,t}$ is the mean genetic diversity, $\sigma_{d}$ the residual standard deviation and $\nu$ the number of degrees of freedom. 

Based on theory, we expect average genetic diversity to decline exponentially with time: 

$$ 
\mu_{x,i,t} =   \mu_{i,t=0} \times  \exp(-\lambda_{x,i} \times t)
$$

The two parameters $\mu_{i,t=0}$ (initial diversity) and  $\lambda_{x,i}$ (rate of decline) depend on replicate, treatment (reference or reduced connectedness) and location (core or front) as follow:

$$
\mathrm{logit}(\mu_{i,t=0}) = \beta_{0} + \alpha_{i}
$$

$$
\log_{10}(\lambda_{x,i}) = \beta_{1[\text{TREATMENT}[i]]}+\beta_{2[\text{TREATMENT[i]}]}(x-0.5) + \gamma_{i} + \zeta_{i}(x-0.5)
$$
(with $\mathrm{logit}$ and $\log_{10}$ transformations here to ensure both parameters stay within bounds). 

Initial diversity is thus independent of treatment and location, and only depends on replicate identity through a random effect $\alpha_{i}$, while the rate of decline $\lambda$ depends on treatment, location and their interaction. (Note the centring of $x$ in the formula, and that $x$ is set to 0.5 at $t$ = 0, so that the effect of location on $\lambda$ cancels out at the start of the experiment, when "core" and "front" are not distinct). In addition, both the average decline rate and the front-core difference depend on replicate, which is accounted for through the random effect parameters $\gamma_{i}$ and $\zeta_{i}$ respectively.

The random effects are distributed as following: 

$$
\begin{bmatrix}
\alpha_{i} \\
\gamma_{i} \\
\zeta_{i} \\
\end{bmatrix} \sim 
\mathrm{MVNormal}(
\begin{bmatrix}
0\\
0\\
0\\
\end{bmatrix},\boldsymbol{\Omega})
$$
with $\boldsymbol{\Omega}$ the covariance matrix:

$$
\boldsymbol{\Omega} = 
\begin{bmatrix}
\sigma_{\alpha} & 0 & 0 \\
0 & \sigma_{\gamma} & 0 \\
0 & 0 & \sigma_{\zeta} \\
\end{bmatrix} 
\times \boldsymbol{\mathrm{R}} \times
\begin{bmatrix}
\sigma_{\alpha} & 0 & 0 \\
0 & \sigma_{\gamma} & 0 \\
0 & 0 & \sigma_{\zeta} \\
\end{bmatrix}
$$
where $\sigma_{\alpha}$, $\sigma_{\gamma}$ and $\sigma_{\zeta}$ are the random effect standard deviations for each parameter, and $\boldsymbol{\mathrm{R}}$ the corresponding correlation matrix.

We used weakly informative priors mostly following McElreath [-@mcelreathStatisticalRethinkingBayesian2020]. For the fixed intercept of the initial diversity $\beta_{0}$, which corresponds to the logit of a proportion, we used a $\mathrm{Normal}(0,1.5)$, which gives a relatively flat prior when converted back to proportions. For all other fixed effects parameters $\beta_{j|j > 0}$, we used a $\mathrm{Normal}(0, 1)$ prior (note that results are overall insensitive to fixing both standard deviations to 1 or to 1.5). All standard deviation parameters $\sigma$ (including the distributional standard deviation $\sigma_{d}$) were attributed the same $\mathrm{Half\mbox{-}Normal}(0,1)$ prior. For the random effect correlation matrix $\boldsymbol{\mathrm{R}}$ we used a $\mathrm{LKJCorr}(2)$ prior, while we used a $\mathrm{Gamma}(2,0.1)$ for the degrees of freedom $\nu$, based on Stan developers recommendations (https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations).

An alternative model can be written, where $H_{x,i,t} \sim \mathrm{Beta}(\mu_{x,i,t}, \phi)$, but it has a lower predictive performance (see Methods in the main text, and details in linked code (main script 1)). Following recommendations for weakly informative priors (https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations), we use there a $\mathrm{Half\mbox{-}Normal}(0,1)$ prior on $1/\phi$ (all other parameters and priors are as described above).

## S5.2 - Genetic diversity, simulated data

In our simulations, it is not possible to analyse genetic diversity using the model(s) described in S5.1, in large part because simulated diversity data contains many zeroes, which means models using either logit transformations or Beta distributions are inappropriate.

As an alternative, we can use the model proposed by Gandhi *et al.* [-@gandhiCooperationMitigatesDiversity2019] in which, for a given treatment and location combination $j$ at a given time $t$ (in generations from release), the expected among-replicate variance in the frequencies of either one of the two alleles $V_{j,t}$ can be described this way:

$$ V_{j,t} \sim \mathrm{Beta}(\mu_{j,t}, \phi)$$

$$ \mu_{j,t} =   V_{\max} \times  (1 - \exp(-\lambda_{j} \times t)) $$ 

where $V_{max}$ is both the asymptotic variance (once all patches have reached fixation) and the product of initial allele frequencies (and so only depends on the initial allelic distribution, not on treatment or patch type), and $\lambda$ a rate of decay of genetic diversity, which varies between treatments and locations (core vs. front) as in the "experimental" model.

We put the same priors on $\log_{10}(\lambda)$ and $1/\phi$  as in the experimental models ($\mathrm{Normal}(0, 1)$ and $\mathrm{Half\mbox{-}Normal}(0, 1)$, respectively), for the same reasons. We put a stronger, informative prior on $\mathrm{logit}(V_{max})$ :

$$ \mathrm{logit}(V_{max}) \sim \mathrm{Normal}(\mathrm{logit}(0.25), 0.5) $$
, as the expected asymptotic among-replicate variance is 0.25 for the case of a randomly distributed and randomly fixating locus with two alleles ($p(1-p)$ with $p$ = 0.5).

## S5.3 - Front velocity, experimental and simulated data

In both experimental and simulation data, the location $X_{i,t}$ of the expansion front of the $i$th replicate after $t$ generations can be modelled as follow:

$$ X_{i,t} \sim \mathrm{Log\mbox{-}Normal}(\ln (v_{i,t} \times t), \sigma_{d}) $$

where $v_{i,y}$ denotes the expansion speed since release, and $\sigma{d}$ is the residual standard deviation of the log-distances.

The expansion speed $v_{i,y}$ can then be modelled as following:

$$v_{i,t} = v_{i,t \to \infty} + (v_{i,t=1} - v_{i,t \to \infty}) \times \exp(-\lambda_{i} \times (t -1))$$

, that is, moving from an initial speed $v_{i,t=1}$ to an equilibrium speed $v_{i,t \to \infty}$, with the rate of "decay" to the asymptotic speed being $\lambda_{i}$.
  
In the experiment, all three parameters depend on treatment, and on replicate identity:

$$
\ln(v_{i,t=1}) = \ln(v_{\text{TREATMENT}[i], t=1}) + \alpha_{i}
$$

$$
\ln(v_{i,t \to \infty}) = \ln(v_{\text{TREATMENT}[i], t \to \infty}) + \gamma_{i}
$$

$$
log_{10}(\lambda_{i}) = log_{10}(\lambda_{\text{TREATMENT}[i]}) + \zeta_{i}
$$

In simulated data, we fixed $v_{i,t=1} = 1$ (see main text for rationale), we logit-transformed $v_{i,t \to \infty}$ rather than log-transforming it (because speeds were constrained between 0 and 1):

$$
\mathrm{logit}(v_{i,t \to \infty}) = \mathrm{logit}(v_{\text{TREATMENT}[i], t \to \infty}) + \gamma_{i}
$$
and we rescaled $(t -1)$ to $(t - 1) /10$ (so expressed elapsed time in 10s of generations), to facilitate convergence while keeping the same weakly informative priors. The model is otherwise unchanged.

In both simulated and experimental data, the random effects $\alpha_{i}$, $\gamma_{i}$ and $\zeta_{i}$ are distributed as following: 

$$
\begin{bmatrix}
\alpha_{i} \\
\gamma_{i} \\
\zeta_{i} \\
\end{bmatrix} \sim 
\mathrm{MVNormal}(
\begin{bmatrix}
0\\
0\\
0\\
\end{bmatrix},\boldsymbol{\Omega})
$$

with $\boldsymbol{\Omega}$ the covariance matrix:

$$
\boldsymbol{\Omega} = 
\begin{bmatrix}
\sigma_{\alpha} & 0 & 0 \\
0 & \sigma_{\gamma} & 0 \\
0 & 0 & \sigma_{\zeta} \\
\end{bmatrix} 
\times \boldsymbol{\mathrm{R}} \times
\begin{bmatrix}
\sigma_{\alpha} & 0 & 0 \\
0 & \sigma_{\gamma} & 0 \\
0 & 0 & \sigma_{\zeta} \\
\end{bmatrix}
$$

where $\sigma_{\alpha}$, $\sigma_{\gamma}$ and $\sigma_{\zeta}$ are the random effect standard deviations for each parameter, and $\boldsymbol{\mathrm{R}}$ the corresponding correlation matrix.

We used the same weakly informative priors for $v_{\mathrm{TREATMENT}[t=1]}$, $v_{\mathrm{TREATMENT}[t \to \infty]}$ and $\lambda_{\mathrm{TREATMENT}}$: $\mathrm{Normal}(0,1)$ for all the fixed effects parameters,  $\mathrm{Half\mbox{-}Normal}(0,1)$ priors for all standard deviations $\sigma$ and a LKJ prior $\mathrm{LKJcorr}(2)$ for the correlation matrix $\boldsymbol{\mathrm{R}}$


# S6 - Summary tables for main text models

We here present posterior means and 95% credible intervals for the fixed effect parameters of the models discussed in the main text. For conciseness, we focus on fixed effect parameters as they are the ones that interest us in the present study; the interested reader can get the same information for random effect and distributional parameters by running the corresponding `Rmd` scripts (scripts 1 and 3), which contains various summary calls. Parameter names are as in **Supplementary Material S5**.

## Expansion velocity

**Table S6.1** Posterior means [95% credible intervals] for the model fitted to analyse expansion speeds of *simulated* range expansions

```{r table6-1}
load(here("R_output", "model3_front_IBM.Rdata"))

mod_front %>%
  posterior_samples() %>%
  select(starts_with("b_")) %>% #we keep only fixed effects coefs
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(entry = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>% #rounding everything for consistency
  mutate(treatment = ifelse(str_detect(name, "reference"), "reference", name)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "density"), "density-dependent dispersal", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "connectedness"), "reduced connectedness", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "Allee"), "weak Allee effect", treatment)) %>%
  mutate(K = ifelse(str_detect(name, "225"), 225, 450)) %>%
  mutate(parameter = str_split_fixed(name, "_", 3)[, 2]) %>%
  select(parameter, K, treatment, entry) %>%
  pivot_wider(names_from = treatment, values_from = entry) %>%
  arrange(parameter == "logitspeedasym") %>%
  mutate(name = c(rep("$\\log_{10}(\\lambda)$", 2), rep("$\\mathrm{logit}(v_{t \\to \\infty})$", 2))) %>%
  mutate(name = paste(name, ", $K$", "=", K, sep = "")) %>%
  select(name, reference, `density-dependent dispersal`, `weak Allee effect`, `reduced connectedness`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```

**Table S6.2** Posterior means [95% credible intervals] for the model fitted to analyse expansion speeds of *experimental* range expansions

```{r table6-2}

load(here("R_output", "model1_front_expe.Rdata"))

mod_front %>%
  posterior_samples() %>%
  select(starts_with("b_")) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(entry = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(treatment = ifelse(str_detect(name, "reference"), "reference", "reduced connectedness")) %>%
  mutate(parameter = str_split_fixed(name, "_", 3)[, 2]) %>%
  select(parameter, treatment, entry) %>%
  pivot_wider(names_from = treatment, values_from = entry) %>%
  mutate(name = c("$\\log_{10}(\\lambda)$", "$\\ln(v_{t \\to \\infty})$", "$\\ln(v_{t = 1})$")) %>%
  select(name, reference, `reduced connectedness`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```

## Genetic diversity


```{r table6-genetdata}
load(here("R_output", "model4_genetics_IBM.Rdata"))
```

**Table S6.3** Posterior means [95% credible intervals] for the model fitted to analyse genetic diversity of *simulated* range expansions

```{r table6-3}
mod_genetics %>%
  posterior_samples() %>%
  select(starts_with(c("b_logdecay"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(entry = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(treatment = ifelse(str_detect(name, "reference"), "reference", name)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "density"), "density-dependent dispersal", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "connectedness"), "reduced connectedness", treatment)) %>%
  mutate(treatment = ifelse(str_detect(treatment, "Allee"), "weak Allee effect", treatment)) %>%
  mutate(K = ifelse(str_detect(name, "225"), 225, 450)) %>%
  mutate(location = ifelse(str_detect(name, "is.frontFALSE"), "core", "edge")) %>%
  mutate(parameter = str_split_fixed(name, "_", 3)[, 2]) %>%
  select(parameter, K, treatment, location, entry) %>%
  pivot_wider(names_from = treatment, values_from = entry) %>%
  mutate(name = c(rep("$\\log_{10}(\\lambda)$", 4))) %>%
  mutate(name = paste(name, ", $K$", "=", K, ", ", location, " patches", sep = "")) %>%
  select(name, reference, `density-dependent dispersal`, `weak Allee effect`, `reduced connectedness`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```

```{r table6-3b}
mod_genetics %>%
  posterior_samples() %>%
  select(starts_with(c("b_logitVmax"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(`all treatments` = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(name = "$\\mathrm{logit}(V_{max})$") %>%
  select(name, `all treatments`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```


**Table S6.4** Posterior means [95% credible intervals] for the model fitted to analyse genetic diversity of *experimental* range expansions

```{r table6-4data}
load(here("R_output", "model2_genet_expe.Rdata"))
```


```{r table6-4}
mod_genetics %>%
  posterior_samples() %>%
  select(starts_with(c("b_logdecay"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(entry = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(treatment = ifelse(str_detect(name, "reference"), "reference", "reduced connectedness")) %>%
  mutate(parameter = ifelse(!str_detect(name, "is.edge"), "average $\\log_{10}$(decay rate of genetic diversity) ($\\beta_{1}$)", "difference edge-core in decay rate ($\\beta_{2}$)")) %>%
  select(parameter, treatment, entry) %>%
  pivot_wider(names_from = treatment, values_from = entry) %>%
  column_to_rownames(var = "parameter") %>%
  kable(format = "html") %>%
  kable_styling()
```

```{r table6-4b}
mod_genetics %>%
  posterior_samples() %>%
  select(starts_with(c("b_logitH0"))) %>%
  pivot_longer(everything()) %>%
  group_by(name) %>%
  mean_hdi() %>%
  mutate(`all treatments` = paste(round(value, 2), " [", round(.lower, 2), ", ", round(.upper, 2), "]", sep = "")) %>%
  mutate(name = "logit of initial genetic diversity ($\\beta_{0}$)") %>%
  select(name, `all treatments`) %>%
  column_to_rownames(var = "name") %>%
  kable(format = "html") %>%
  kable_styling()
```


# S7 - By how many individuals are new populations founded (in simulations)?

One of our main simulation results is that range expansions with reduced connectedness are pushed (based on velocity ratios) and yet lose diversity faster than reference expansions. To better understand this, we looked at $N_{X+1,t+1}$, the number of individuals one patch ahead of the current front patch $X$, one generation later (after the immigration phase and before reproduction). As we are interested in the size of new populations, we discard cases where $N_{X+1,t+1} = 0$, which correspond to dispersal failures and no new front population. In addition, we focused on “reference” and “reduced connectedness” treatments for simplicity, and discarded data from $t = 1$, as individuals can only move in one direction at the very start of the experiment.

We first analysed  $N_{X+1,t+1}$ as a function of treatment and $K$, as well as their interactions. To do so, we used a negative binomial GLMM with the aforementioned variables as fixed effects and replicate identity as a random effect. To work around the fact our data are zero-truncated, two solutions are possible: either include the truncation in-model, or instead model $N_{X+1,t+1} - 1$. We chose the latter approach due to simplicity, but both can easily be implemented and lead to the same results.

Assuming fixed deterministic dispersal rates, the number of individuals founding a new population at the front $N_{X+1,t+1}$ should be $N_{X,t} \times 0.5 D_{0}$ (0.5 because dispersers can move into either direction, so only half, on average, can contribute to founding a new front population). But because of dispersal stochasticity leading to dispersal failures (**Fig.1** main text), the actual number of founders should be different (higher, to "compensate" for all dispersal failures and keep the "nominal" dispersal rate).
So in a second step, we analysed how the ratio $N_{X+1,t+1}/(N_{X,t} \times 0.5 D_{0})$ varied with treatment and $K$, as well as their interactions, using a lognormal GLMM, with again a random effect of replicate identity.


```{r importing-suppl-data}
data <- read_csv(file = here("NetLogo_output/model-output_supplementary.csv"))
```

```{r propagule-models}

tab_propa <- data %>%
  filter(treatment == "reference" | treatment == "reduced connectedness") %>%
  mutate(K = factor(K), replicateID = paste(treatment, K, seedID)) %>%
  select(treatment, replicateID, ticks, K, is.front, N_predispersal, N_postdispersal, disp0_mean) %>%
  pivot_wider(names_from = is.front, values_from = c(N_predispersal, N_postdispersal)) %>%
  filter(N_predispersal_TRUE == 0, ticks > 1) %>% ## we only keep case where the front advanced (new pops, so no individuals in focal potential front (is.front==TRUE), prior to the dispersal phase)
  select(treatment, replicateID, ticks, K, N_source = N_predispersal_FALSE, N_founders = N_postdispersal_TRUE, disp0_mean)

if (file.exists(here("R_output", "supplementary", "model_S7_sizefront_IBM.Rdata"))) {
  load(here("R_output", "supplementary", "model_S7_sizefront_IBM.Rdata"))
} else {
  mod_propa1 <- brm(bf(
    N_founders - 1 ~ 0 + treatment:K + (1 | replicateID),
    nlf(shape ~ 1 / invshape),
    invshape ~ 1
  ),
  family = negbinomial(link_shape = "identity"), data = tab_propa,
  prior = c(
    set_prior("normal(0,5)", class = "b"),
    set_prior("normal(0,1)", class = "sd"),
    set_prior("normal(0,1)", nlpar = "invshape")
  ), chains = 4, seed = 42, iter = 4000,
  control = list(adapt_delta = 0.95)
  )


  mod_propa2 <- brm(bf(N_founders / (N_source * 0.5 * disp0_mean) ~ 0 + treatment:K + (1 | replicateID)),
    family = lognormal, data = tab_propa,
    prior = c(
      set_prior("normal(0,1)", class = "b"),
      set_prior("normal(0,1)", class = "sd"),
      set_prior("normal(0,1)", class = "sigma")
    ), chains = 4, seed = 42, iter = 6000,
    control = list(adapt_delta = 0.95)
  )

  save(list = c("mod_propa1", "mod_propa2"), file = here("R_output", "supplementary", "model_S7_sizefront_IBM.Rdata"))
}
```


We found that the average new front population was founded by fewer individuals in reduced connectedness landscapes (**Supplementary Figure S7.1**), likely explaining why genetic diversity decayed faster, as the effective population size would also be lower. 

```{r figure-7-1}
tab_propa %>%
  mutate(replicateID = replicateID[1]) %>%
  mutate(treatment = relevel(factor(treatment), ref = "reference")) %>%
  select(treatment, K, replicateID) %>%
  distinct() %>%
  add_fitted_draws(mod_propa1, re_formula = NA) %>%
  ggplot() +
  stat_eye(aes(x = treatment, y = .value + 1, fill = treatment), .width = c(0.66, 0.95), slab_alpha = 0.9, point_interval = mean_hdi) +
  scale_y_continuous("front population size at establishment (posterior mean)") +
  scale_x_discrete("landscape type") +
  scale_fill_manual(values = TRTpalette) +
  facet_wrap(~ paste("K = ", K)) +
  theme_bw() +
  theme(legend.position = "none")
```

**Supplementary Figure S7.1**  Posterior distribution of the mean size of newly founded populations in simulations. Colored areas: posterior distribution; black dots and segments: posterior mean and 66/95% credible intervals.

However, based on our second model, the ratio between "observed" and "expected" founding population sizes is on average higher in “reduced connectedness” landscapes (**Supplementary Figure S7.2**). This, to our opinion, solves the apparent paradox of reduced connectedness: these waves do send more individuals to front patches than expected based on their base dispersal rate. However, at the dispersal rates we considered, this is not enough to compensate the negative effect of the lower dispersal rate itself, hence the faster decay of genetic diversity.


```{r figure-7-2}
tab_propa %>%
  mutate(replicateID = replicateID[1]) %>%
  mutate(treatment = relevel(factor(treatment), ref = "reference")) %>%
  select(treatment, K, replicateID) %>%
  distinct() %>%
  add_fitted_draws(mod_propa2, re_formula = NA) %>%
  ggplot() +
  stat_eye(aes(x = treatment, y = .value, fill = treatment), .width = c(0.66, 0.95), slab_alpha = 0.9, point_interval = mean_hdi) +
  scale_y_continuous("size of new population, relative to deterministic expectation") +
  scale_x_discrete("landscape type") +
  scale_fill_manual(values = TRTpalette) +
  facet_wrap(~ paste("K = ", K)) +
  theme_bw() +
  theme(legend.position = "none")
```

**Supplementary Figure S7.2**.  Posterior distribution of the average ratio between the size of newly founded front populations in simulations and the expected size assuming deterministic dispersal.Colored areas: posterior distribution; black dots and segments: posterior mean and 66/95% credible intervals.

# S8 - Testing the effect of combining density-dependent dispersal and reduced connectedness in simulations

To tentatively explain why, in our experiments, pushed wave fronts created by reduced connectedness lost less genetic diversity than reference landscape fronts, when our first simulations indicate they should not, we ran an additional simulation scenario (see main text discussion for rationale). In this scenario, both the base dispersal rate and the slope of the density-dispersal relationship were changed compared to the reference ($D_{0}=0.1$, $\beta_{density}=1$), leading to a reaction norm where dispersal rates are reduced by 50% at low densities, but similar to the reference scenario at population sizes close to $K$ ($D_{K} \approx 0.23$). We ran this scenario under the same conditions of $K$ and number of replicates as the scenarios presented in the main text, and re-fitted the statistical models presented in the main text including it.

We show that this new scenario leads to pushed waves, based on relative velocities (**Supplementary Figure S8.1**). We also show that, contrary to the simple “reduced connectedness” scenario, it results in a slower loss of genetic diversity than in the reference scenario (**Supplementary Figure S8.2**). Interestingly, compared to the simple “reduced connectedness” scenario again, this one resulted in absolute front velocities much closer to the reference scenario (**Supplementary Figure S8.1**), a feature that is closer to matching results from experimental landscapes.


```{r importing-data-S8}
data <- read_csv(file = here("NetLogo_output/model-output.csv"))
```

```{r processing-data-S8}
data_genetics <- data %>%
  group_by(ticks, treatment, is.front, K) %>%
  summarise(varP1 = var(P1), varP0 = var(P0)) %>%
  mutate(K = factor(K)) ## same as main text, but we keep the supplementary treatment

data_front <- data %>%
  filter(is.front == TRUE) %>%
  mutate(front = pxcor) %>%
  mutate(K = factor(K))
```

```{r model-genetics-S8}
if (file.exists(here("R_output", "supplementary", "model_S8_genetics_IBM.Rdata"))) {
  load(here("R_output", "supplementary", "model_S8_genetics_IBM.Rdata"))
} else {
  prior_genetics <- c(
    set_prior("normal(-1.1,0.5)", nlpar = c("logitVmax")), # informative prior (logit(0.25)=-1.1 (more or less))
    set_prior("normal(0,1)", nlpar = c("logdecay"), class = "b"),
    set_prior("normal(0,1)", nlpar = "invphi", lb = 0)
  )

  bf_genetics <- bf(varP1 ~ logit(Vmax * (1 - exp(-(ticks) * decay))),
    nlf(Vmax ~ inv_logit(logitVmax)),
    nlf(decay ~ 10^(logdecay)),
    logitVmax ~ 1,
    logdecay ~ 0 + treatment:is.front:K,
    nlf(phi ~ 1 / invphi),
    invphi ~ 1,
    family = Beta(link_phi = "identity"), nl = TRUE
  )

  mod_genetics <- brm(bf_genetics,
    data = data_genetics,
    iter = 2000, chains = 4,
    prior = prior_genetics, seed = 42
  )

  save(list = "mod_genetics", file = here("R_output", "supplementary", "model_S8_genetics_IBM.Rdata"))
}
```


```{r model-front-S8}
prior_front <- c(
  # set_prior("normal(0,1)",nlpar="logitspeedstart",class="b"), #prior not needed because we fix start speed to 1
  set_prior("normal(0,1.5)", nlpar = "logitspeedasym", class = "b"),
  set_prior("normal(0,1)", nlpar = "lograte", class = "b"),
  set_prior("normal(0,1)", nlpar = "logitspeedasym", class = "sd"),
  set_prior("normal(0,1)", nlpar = "lograte", class = "sd"),
  set_prior("normal(0,1)", class = "sigma"),
  set_prior("lkj(2)", class = "cor")
)

bf_front <- bf(front ~ log(speed * ticks),
  nlf(speed ~ speedasym + (1 - speedasym) * exp(-((ticks - 1) / 10) * rate)), ## speedstart forced to 1
  nlf(rate ~ 10^(lograte)),
  nlf(speedasym ~ inv_logit(logitspeedasym)),
  logitspeedasym ~ 0 + treatment:K + (1 | 1 | replicateID),
  lograte ~ 0 + treatment:K + (1 | 1 | replicateID),
  family = lognormal, nl = TRUE
)
```


```{r model-front-S8-fit}

data_front_part <- data_front %>% filter((ticks %% 5) == 0)

if (file.exists(here("R_output", "supplementary", "model_S8_front_IBM.Rdata"))) {
  load(here("R_output", "supplementary", "model_S8_front_IBM.Rdata"))
} else {
  mod_front <- brm(bf_front,
    data = data_front_part,
    chains = 4, iter = 6000, warmup = 2000,
    prior = prior_front,
    seed = 42
  )

  save(list = "mod_front", file = here("R_output", "supplementary", "model_S8_front_IBM.Rdata"))
}
```


```{r figure-S8-1, fig.width=10}

thresholds <- data_front %>%
  mutate(threshold_pushed = (3 / (2 * sqrt(2))) * v_f) %>%
  select(K, treatment, v_f, threshold_pushed) %>%
  distinct() %>%
  pivot_longer(
    cols = c(v_f, threshold_pushed),
    values_to = "threshold_value", names_to = "threshold_type"
  ) %>%
  mutate(threshold_type = fct_recode(threshold_type,
    vF = "v_f",
    `3/(2 x sqrt(2))) x vF` = "threshold_pushed"
  )) %>%
  mutate(treatment = fct_relevel(treatment, "reduced + DDD", after = Inf))


data_front %>%
  mutate(treatment = relevel(factor(treatment), ref = "reference")) %>%
  mutate(treatment = fct_relevel(treatment, "reduced connectedness", after = Inf)) %>%
  mutate(treatment = fct_relevel(treatment, "reduced + DDD", after = Inf)) %>%
  # filter(treatment != "reduced + DDD") %>%
  ungroup() %>%
  mutate(replicateID = replicateID[1], ticks = 1) %>%
  select(treatment, ticks, replicateID, K) %>%
  distinct() %>%
  add_fitted_draws(mod_front, nlpar = "logitspeedasym", re_formula = NA) %>%
  mutate(.value = invlogit(.value)) %>%
  ggplot() +
  geom_hline(data = thresholds, aes(yintercept = threshold_value, lty = threshold_type)) +
  stat_eye(aes(x = factor(K), group = K, y = .value), normalize = "xy") +
  scale_y_continuous("Asymptotic velocity (posterior)") +
  scale_x_discrete("equilibrium population size K") +
  scale_linetype_discrete(
    name = "",
    labels = c(
      expression(paste(frac(3, 2 * sqrt(2)), "  ", italic(v[F]))),
      expression(italic(v[F]))
    )
  ) +
  facet_grid(cols = vars(treatment)) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95") +
  theme(legend.title = element_blank(), legend.position = c(0.86, 0.3), legend.background = element_rect(fill = "white", colour = "black"), legend.margin = margin(t = 2, r = 2, l = 2, b = 2))
```


**Supplementary Figure S8.1** : Posterior distribution of the asymptotic front velocity ($v$) in simulations, depending on simulation scenario and equilibrium population size $K$. The horizontal lines mark the range between $v/v_{F} = 1$ (i.e. pulled waves) and $v/v_{F} = 3 / 2 \sqrt 2$ (limit between semi-pushed and fully pushed waves).

```{r figure-s8-2, fig.width=10}

data_genetics %>%
  ungroup() %>%
  mutate(treatment = relevel(factor(treatment), ref = "reference")) %>%
  mutate(treatment = fct_relevel(treatment, "reduced connectedness", after = Inf)) %>%
  mutate(treatment = fct_relevel(treatment, "reduced + DDD", after = Inf)) %>%
  # filter(treatment != "reduced + DDD") %>%
  select(treatment, is.front, K) %>%
  mutate(Location = factor(is.front)) %>%
  mutate(Location = fct_recode(Location, front = "TRUE", core = "FALSE")) %>%
  mutate(Location = fct_relevel(Location, "front", "core")) %>%
  distinct() %>%
  mutate(ticks = 1) %>%
  add_fitted_draws(mod_genetics, re_formula = NA, nlpar = "logdecay") %>%
  mutate(.value = 10^(.value)) %>%
  ggplot() +
  stat_eye(aes(x = K, fill = Location, group = Location, y = .value), position = "dodge", normalize = "xy") +
  facet_grid(cols = vars(treatment), rows = vars(Location), scales = "free_y") +
  scale_y_continuous(name = expression(paste("genetic diversity decay rate  ", lambda))) +
  scale_x_discrete("equilibrium population size K") +
  scale_fill_manual("Location", values = edgecorePalette) +
  theme_half_open(11) +
  background_grid(colour.major = "grey95", colour.minor = "grey95") +
  theme(legend.position = "none")
```

**Supplementary Figure S8.2** : Posterior distribution of the decay rate of genetic with time ($\lambda$) in simulations, depending on simulation scenario, equilibrium population size $K$ and patch location (either the original release site (core) or the most advanced patch at the time of measure (front)). Please note that posterior for core and front patches are displayed on different scales on the y-axis, for readability.

# S9 - Differences in equilibrium population size between experimental treatments (a partial and preliminary look)

We used a Beta generalized linear mixed model to determine whether *Trichogramma* population sizes (computer-estimated parasitism rates) at equilibrium differed between our two experimental treatments. For the purpose of this preliminary analysis, we focused for simplicity on the release patch only, which we expected to be at equilibrium more or less from the start of the experiment given release densities. Our model included fixed effects of experimental treatment, as well as random effects of observation macro (to account for systematic macro bias, see **Supplementary Figure S2.1**) and replicate identity.

```{r popsizeS9}
raw_dynamics <- read_csv(here("data", "Trichogramma_dynamics.csv"))

data_popsize_temp <- raw_dynamics %>%
  mutate(
    Mix = as.numeric(str_sub(Image, 1, 1)),
    Treatment = str_sub(Image, 2, 3),
    Replicate = as.numeric(str_sub(Image, 4, 4)),
    Patch = as.numeric(str_sub(Image, 6, 7))
  ) %>%
  # no further processing needed; we exploit the fact that chars 6&7 are either digit dot (patches 0 to 9)
  # or digit-digit (patches 10 and beyond)
  ## as.numeric() resolves both correctly (e.g; "2." and "12" become 2 and 12)
  mutate(landscapeID = paste("Mix", Mix, "_Treatment", Treatment, "_Replicate", Replicate, sep = "")) %>% # a unique replicate ID
  mutate(
    Peggs_est = P / (P + H), ## proportion of pixels counted as parasitised (estimated)
    spacetimeID = paste(landscapeID, "_Generation", Generation, "_Patch", Patch, sep = ""), # a unique ID for each replicate x patch x generation combination
    Mix = factor(Mix)
  ) %>%
  mutate(Treatment = fct_recode(Treatment, `reference` = "PL", `reduced connectedness` = "PS"))


data_popsize <- data_popsize_temp %>%
  group_by(Generation, landscapeID) %>%
  filter(Patch == 0) ## we only keep the release patch
```


```{r popsizeS9-model}
if (file.exists(here("R_output", "supplementary", "model_S9_popsize.Rdata"))) {
  load(here("R_output", "supplementary", "model_S9_popsize.Rdata"))
} else {
  mod_popsize <- brm(bf(
    Peggs_est ~ 0 + Treatment + (1 | Macro) + (1 | landscapeID),
    nlf(phi ~ 1 / invphi),
    invphi ~ 1
  ),
  data = data_popsize, family = Beta(link_phi = "identity"),
  iter = 4000, warmup = 2000, chains = 4,
  prior = c(
    set_prior("normal(0,1.5)", class = "b"),
    set_prior("normal(0,1)", class = "sd"),
    set_prior("normal(0,1)", nlpar = "invphi", lb = 0)
  ),
  control = list(adapt_delta = 0.99, max_treedepth = 15), seed = 42
  )

  save(list = "mod_popsize", file = here("R_output", "supplementary", "model_S9_popsize.Rdata"))
}
```


```{r popsizeS9-figure}
newdata <- data_popsize %>%
  ungroup() %>%
  mutate(Macro = Macro[1], landscapeID = landscapeID[1]) %>% # it's just a placeholder, we plot the posterior for the "true" (grand) mean distance, without random effects
  select(Macro, Treatment) %>%
  distinct()


p1 <- newdata %>%
  add_fitted_draws(mod_popsize, re_formula = NA) %>%
  ggplot() +
  stat_eye(aes(x = Treatment, y = .value, fill = Treatment), .width = c(0.66, 0.95), slab_alpha = 0.9, point_interval = mean_hdi) +
  scale_fill_manual(values = TRTpalette) +
  scale_x_discrete("") +
  scale_y_continuous("Mean population size in core patches (in % of total hosts)", limits = c(0, 1)) +
  theme_bw()

## a subplot showing the difference between treatments
p2 <- newdata %>%
  add_fitted_draws(mod_popsize, re_formula = NA) %>%
  ungroup() %>%
  compare_levels(variable = .value, by = Treatment) %>%
  ggplot() +
  stat_eye(aes(x = Treatment, y = .value), .width = c(0.66, 0.95), fill = "grey", point_interval = mean_hdi) +
  scale_x_discrete("", labels = "") +
  scale_y_continuous("Difference between treatments",
    limits = c(0, 1) - invlogit(fixef(mod_popsize)["Treatmentreference", "Estimate"])
  ) + ## so the "difference" subplot is aligned with the main
  geom_hline(yintercept = 0, lty = 2) +
  theme_bw()


diffs <- newdata %>%
  add_fitted_draws(mod_popsize, re_formula = NA) %>%
  ungroup() %>%
  compare_levels(variable = .value, by = Treatment) %>%
  mutate(.diff = .value) %>%
  ungroup() %>%
  select(-c(.value, Treatment))

diffs_rel <- newdata %>%
  add_fitted_draws(mod_popsize, re_formula = NA) %>%
  ungroup() %>%
  filter(Treatment == "reference") %>%
  left_join(diffs) %>%
  mutate(.value = .diff / .value) %>%
  mean_hdi(.value)
```

We found that equilibrium population sizes were higher when connectedness was reduced than in reference landscapes, with the average parasitism rate in the former being `r round(100+100*diffs_rel$.value[1],2)`% [`r round(100+100*diffs_rel$.lower[1],2)`, `r round(100+100*diffs_rel$.upper[1],2)`] of the average in the latter (**Supplementary Figure S9.1**). The model is not perfect (you can see that by looking at posterior checks using `pp_check()`), but it is good enough for this preliminary side analysis. After all, either the pattern seen **Supplementary Figure S9.1** persists with a better model, and in that case the discussion around it in the main text stands, or the pattern vanishes, and in that case there is no need to work around $K$ differences in our explanations and discussions.


```{r}
p1 + p2 + plot_layout(guides = "collect", widths = c(4, 1)) & theme_bw() &
  theme(legend.position = "none")
```

**Supplementary Figure S9.1** Left: Mean population size (estimated as host parasitism rate 7 days post-adult removal) as a function of treatment. Colored areas: posterior distribution; black dots and segments: posterior mean and 66/95% credible intervals. Right: posterior difference between the two experimental treatments.

# S10 - Model descriptions for models presented in Supplementary Materials

(As in S5, all Beta models described here use the (mean, precision) parametrisation of the Beta distribution.)

## S10.1 - validation of computer estimates of population sizes (Supplementary Material S2)

To analyse for each available patch $i$ computer estimates of parasitism rate $P_{i,m}$ (where $m$ is the estimating computer macro) with human counts of parasitised eggs $n_{i}$, we used the following bivariate mixed model:

$$
n_{i} \sim \mathrm{Binomial}(N = 450, p_{i}) \\
P_{i,m} \sim \mathrm{Beta}(\mu_{i}, \phi) \\
\mathrm{logit}(p_{i}) = \beta_{0} + \alpha_{i} \\
\mathrm{logit}(\mu_{i}) = \beta_{1} + \gamma_{i} \\
$$

The patch-level random effects $\alpha$ and $\gamma$ are correlated and distributed as follow:

$$
\begin{bmatrix}
\alpha_{i} \\
\gamma_{i} \\
\end{bmatrix} \sim 
\mathrm{MVNormal}(
\begin{bmatrix}
0\\
0\\
\end{bmatrix},\boldsymbol{\Omega}) \\
\boldsymbol{\Omega} = 
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\gamma} \\
\end{bmatrix} 
\times \boldsymbol{\mathrm{R}} \times
\begin{bmatrix}
\sigma_{\alpha} & 0 \\
0 & \sigma_{\gamma} \\
\end{bmatrix} \\
$$
, where $\Omega$ and $\boldsymbol{\mathrm{R}}$ again refer the the covariance and correlation matrices, respectively. As in similar models described above, we use a $\mathrm{Normal}(0,1.5)$ for fixed effect ($\beta$) parameters, a $\mathrm{Half\mbox{-}Normal}(0,1)$ prior for standard deviations $\sigma$ and for $1/\phi$, and a $\mathrm{LKJCorr}(2)$ prior for the correlation matrix $\boldsymbol{\mathrm{R}}$. 

We ran a second version of this model, to determine whether computer macros presented systematic estimation biases. In this case, the parameter $\beta_{1}$, which denotes the (logit-transformed) average parasitism rate in the "computer estimates" model, was simply changed to be macro-specific: 
$$
P_{i,m} \sim \mathrm{Beta}(\mu_{i,m}, \phi) \\
\mathrm{logit}(\mu_{i,m}) = \beta_{1[m]} + \gamma_{i}\\
$$
, with the remaining of the model remaining unchanged.

## S10.2 -  Validation of the experimental design (Supplementary Material S3)

We analysed the mean distance from release $\bar{D}_{i,m}$ between the eggs laid in a replicate $i$ (as seen from macro $m$) and the corresponding parental patch using data from the starting generation, when there were only 5 patches per replicate (including the release patch). This means $\bar{D}_{i,m}$ can only take values in the $\left]0, 4\right[$ range, and can be modelled as follow:

$$ 
\frac{\bar{D}_{i,m}}{4} \sim \mathrm{Beta}(\mu_{i,m}, \phi) \\
\mathrm{logit}(\mu_{i,m})= \beta_{\text{TREATMENT}[i]} + \alpha_{m}\\
\alpha_{m} \sim \mathrm{Normal}(0,\sigma_{\alpha}) \\
$$
As in other Beta models, we used a $\mathrm{Normal}(0,1.5)$ prior for the treatment-specific intercepts $\beta$, and $\mathrm{Half\mbox{-}Normal}(0,1)$ priors for both the random effect standard deviation $\sigma_{\alpha}$ and $1/\phi$.

## S10.3 - By how many individuals are new populations founded? (Supplementary Material S7)

We first analysed the way the number of individuals founding a new front population varied depending on treatment (i.e. scenario × $K$), using a negative binomial GLMM (the "-1" is here to account for the zero truncation, as we do not analyse dispersal failures):
$$
N_{i,X+1,t+1}-1 \sim \mathrm{NegativeBinomial}(\mu_{i}, \phi) \\
\log(\mu_{i}) = \beta_{\mathrm{TREATMENT[i]}} + \alpha_{i} \\
\alpha_{i} \sim \mathrm{Normal}(0,\sigma_{\alpha})
$$
We use a  $\mathrm{Normal}(0,5)$ for $\beta$ (larger prior $\sigma$ in most other models in this document, as we could reasonably expect mean population sizes to be higher than $\exp(1)$), and a $\mathrm{Half\mbox{-}Normal}(0,1)$ for both $\sigma_{\alpha}$ and $1/\phi$, as in previous models.

We then analyzed the effect of simulation treatment on the ratio between the "actual" number of individuals founding a new population and the expectation assuming deterministic dispersal, using a lognormal GLMM:
$$
N_{i,X+1,t+1}/(N_{i,X,t} \times 0.5 D_{0}) \sim \mathrm{Log\mbox{-}Normal}(\mu_{i}, \sigma_{d})\\
\mu_{i} = \beta_{\mathrm{TREATMENT[i]}} + \alpha_{i} \\
\alpha_{i} \sim \mathrm{Normal}(0,\sigma_{\alpha})
$$
, using a $\mathrm{Normal}(0,1)$  for $\beta$ and  and a $\mathrm{Half\mbox{-}Normal}(0,1)$ for both $\sigma$.

## S10.4 - Testing the effect of combining density-dependent dispersal and reduced connectedness in simulations (Supplementary Material S8)

See S5.2 and S5.3

## S10.5 - Differences in equilibrium population size between experimental treatments (Supplementary Material S9)

We assumed the parasitism rate in the release patch $P_{i,t,m}$ observed by macro $m$ in replicate $i$ after $t$ generations can be modelled as follow:

$$ 
P_{i,t,m} \sim \mathrm{Beta}(\mu_{i,t,m}, \phi) \\
\mu_{i,t,m} = \beta_{\text{TREATMENT}[i]} +\alpha_{i} + \gamma_{m}\\
\alpha_{i} \sim \mathrm{Normal}(0,\sigma_{\alpha}) \\
\gamma_{m} \sim \mathrm{Normal}(0,\sigma_{\gamma}) \\
$$
, where $\alpha$ denote random effects of replicate and $\gamma$ random effects accounting for systematic between-macro differences. Priors were the same as in previous Beta models, that is a $\mathrm{Normal}(0,1.5)$ for $\beta$s, and a $\mathrm{Half\mbox{-}Normal}(0,1)$ for both random effect standard deviations $\sigma$ and for $1/\phi$.

# References
